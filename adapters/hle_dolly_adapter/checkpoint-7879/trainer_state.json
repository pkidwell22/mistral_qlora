{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.9999365441969668,
  "eval_steps": 500,
  "global_step": 7879,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 4.056859493255615,
      "learning_rate": 0.00019979692854423152,
      "loss": 1.7706,
      "step": 10
    },
    {
      "epoch": 0.0,
      "grad_norm": 5.141281604766846,
      "learning_rate": 0.000199593857088463,
      "loss": 1.7071,
      "step": 20
    },
    {
      "epoch": 0.0,
      "grad_norm": 8.676201820373535,
      "learning_rate": 0.0001993400177687524,
      "loss": 1.7188,
      "step": 30
    },
    {
      "epoch": 0.01,
      "grad_norm": 5.451173782348633,
      "learning_rate": 0.00019908617844904177,
      "loss": 1.5928,
      "step": 40
    },
    {
      "epoch": 0.01,
      "grad_norm": 3.5235838890075684,
      "learning_rate": 0.00019883233912933114,
      "loss": 1.7448,
      "step": 50
    },
    {
      "epoch": 0.01,
      "grad_norm": 4.383916854858398,
      "learning_rate": 0.0001985784998096205,
      "loss": 1.6285,
      "step": 60
    },
    {
      "epoch": 0.01,
      "grad_norm": 4.116147041320801,
      "learning_rate": 0.0001983246604899099,
      "loss": 1.4687,
      "step": 70
    },
    {
      "epoch": 0.01,
      "grad_norm": 6.04043436050415,
      "learning_rate": 0.00019807082117019928,
      "loss": 1.5727,
      "step": 80
    },
    {
      "epoch": 0.01,
      "grad_norm": 6.047487735748291,
      "learning_rate": 0.00019781698185048865,
      "loss": 1.5861,
      "step": 90
    },
    {
      "epoch": 0.01,
      "grad_norm": 4.0322394371032715,
      "learning_rate": 0.00019756314253077803,
      "loss": 1.5689,
      "step": 100
    },
    {
      "epoch": 0.01,
      "grad_norm": 13.61977481842041,
      "learning_rate": 0.0001973093032110674,
      "loss": 1.4354,
      "step": 110
    },
    {
      "epoch": 0.02,
      "grad_norm": 6.201426982879639,
      "learning_rate": 0.0001970554638913568,
      "loss": 1.5462,
      "step": 120
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.872925758361816,
      "learning_rate": 0.00019680162457164614,
      "loss": 1.4847,
      "step": 130
    },
    {
      "epoch": 0.02,
      "grad_norm": 4.0786824226379395,
      "learning_rate": 0.00019654778525193554,
      "loss": 1.612,
      "step": 140
    },
    {
      "epoch": 0.02,
      "grad_norm": 3.234367847442627,
      "learning_rate": 0.0001962939459322249,
      "loss": 1.5145,
      "step": 150
    },
    {
      "epoch": 0.02,
      "grad_norm": 5.581273555755615,
      "learning_rate": 0.00019604010661251428,
      "loss": 1.2159,
      "step": 160
    },
    {
      "epoch": 0.02,
      "grad_norm": 3.5188817977905273,
      "learning_rate": 0.00019578626729280368,
      "loss": 1.2908,
      "step": 170
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.8481829166412354,
      "learning_rate": 0.00019553242797309302,
      "loss": 1.585,
      "step": 180
    },
    {
      "epoch": 0.02,
      "grad_norm": 4.349628925323486,
      "learning_rate": 0.00019527858865338242,
      "loss": 1.5624,
      "step": 190
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.0890040397644043,
      "learning_rate": 0.0001950247493336718,
      "loss": 1.4755,
      "step": 200
    },
    {
      "epoch": 0.03,
      "grad_norm": 5.047345161437988,
      "learning_rate": 0.00019477091001396117,
      "loss": 1.5127,
      "step": 210
    },
    {
      "epoch": 0.03,
      "grad_norm": 5.990634918212891,
      "learning_rate": 0.00019451707069425056,
      "loss": 1.5774,
      "step": 220
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.909884214401245,
      "learning_rate": 0.0001942632313745399,
      "loss": 1.3951,
      "step": 230
    },
    {
      "epoch": 0.03,
      "grad_norm": 3.950106382369995,
      "learning_rate": 0.0001940093920548293,
      "loss": 1.5659,
      "step": 240
    },
    {
      "epoch": 0.03,
      "grad_norm": 3.016521692276001,
      "learning_rate": 0.00019375555273511868,
      "loss": 1.4319,
      "step": 250
    },
    {
      "epoch": 0.03,
      "grad_norm": 4.106276988983154,
      "learning_rate": 0.00019350171341540805,
      "loss": 1.5006,
      "step": 260
    },
    {
      "epoch": 0.03,
      "grad_norm": 4.689296245574951,
      "learning_rate": 0.00019324787409569742,
      "loss": 1.3364,
      "step": 270
    },
    {
      "epoch": 0.04,
      "grad_norm": 4.107707500457764,
      "learning_rate": 0.00019299403477598682,
      "loss": 1.6156,
      "step": 280
    },
    {
      "epoch": 0.04,
      "grad_norm": 4.7665839195251465,
      "learning_rate": 0.0001927401954562762,
      "loss": 1.5355,
      "step": 290
    },
    {
      "epoch": 0.04,
      "grad_norm": 4.120604038238525,
      "learning_rate": 0.00019248635613656556,
      "loss": 1.3284,
      "step": 300
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.8589324951171875,
      "learning_rate": 0.00019223251681685494,
      "loss": 1.4431,
      "step": 310
    },
    {
      "epoch": 0.04,
      "grad_norm": 5.26614236831665,
      "learning_rate": 0.0001919786774971443,
      "loss": 1.5212,
      "step": 320
    },
    {
      "epoch": 0.04,
      "grad_norm": 4.265896320343018,
      "learning_rate": 0.0001917248381774337,
      "loss": 1.7025,
      "step": 330
    },
    {
      "epoch": 0.04,
      "grad_norm": 3.6389594078063965,
      "learning_rate": 0.00019147099885772305,
      "loss": 1.4241,
      "step": 340
    },
    {
      "epoch": 0.04,
      "grad_norm": 3.973055601119995,
      "learning_rate": 0.00019121715953801245,
      "loss": 1.5596,
      "step": 350
    },
    {
      "epoch": 0.05,
      "grad_norm": 7.431076526641846,
      "learning_rate": 0.00019096332021830182,
      "loss": 1.5866,
      "step": 360
    },
    {
      "epoch": 0.05,
      "grad_norm": 4.310948848724365,
      "learning_rate": 0.0001907094808985912,
      "loss": 1.5295,
      "step": 370
    },
    {
      "epoch": 0.05,
      "grad_norm": 3.0361454486846924,
      "learning_rate": 0.0001904556415788806,
      "loss": 1.5145,
      "step": 380
    },
    {
      "epoch": 0.05,
      "grad_norm": 4.049889087677002,
      "learning_rate": 0.00019020180225916993,
      "loss": 1.5794,
      "step": 390
    },
    {
      "epoch": 0.05,
      "grad_norm": 3.8251988887786865,
      "learning_rate": 0.00018994796293945933,
      "loss": 1.3107,
      "step": 400
    },
    {
      "epoch": 0.05,
      "grad_norm": 3.8527586460113525,
      "learning_rate": 0.0001896941236197487,
      "loss": 1.5001,
      "step": 410
    },
    {
      "epoch": 0.05,
      "grad_norm": 3.509805679321289,
      "learning_rate": 0.00018944028430003808,
      "loss": 1.4209,
      "step": 420
    },
    {
      "epoch": 0.05,
      "grad_norm": 5.499665260314941,
      "learning_rate": 0.00018918644498032748,
      "loss": 1.1636,
      "step": 430
    },
    {
      "epoch": 0.06,
      "grad_norm": 5.281644821166992,
      "learning_rate": 0.00018893260566061685,
      "loss": 1.5287,
      "step": 440
    },
    {
      "epoch": 0.06,
      "grad_norm": 8.512526512145996,
      "learning_rate": 0.00018867876634090622,
      "loss": 1.3217,
      "step": 450
    },
    {
      "epoch": 0.06,
      "grad_norm": 5.182275295257568,
      "learning_rate": 0.0001884249270211956,
      "loss": 1.3971,
      "step": 460
    },
    {
      "epoch": 0.06,
      "grad_norm": 5.096859931945801,
      "learning_rate": 0.00018817108770148496,
      "loss": 1.3917,
      "step": 470
    },
    {
      "epoch": 0.06,
      "grad_norm": 5.284974575042725,
      "learning_rate": 0.00018791724838177433,
      "loss": 1.3692,
      "step": 480
    },
    {
      "epoch": 0.06,
      "grad_norm": 3.3732035160064697,
      "learning_rate": 0.00018766340906206373,
      "loss": 1.5411,
      "step": 490
    },
    {
      "epoch": 0.06,
      "grad_norm": 4.687380790710449,
      "learning_rate": 0.0001874095697423531,
      "loss": 1.4797,
      "step": 500
    },
    {
      "epoch": 0.06,
      "grad_norm": 5.358977794647217,
      "learning_rate": 0.00018715573042264247,
      "loss": 1.4395,
      "step": 510
    },
    {
      "epoch": 0.07,
      "grad_norm": 6.7021684646606445,
      "learning_rate": 0.00018690189110293185,
      "loss": 1.593,
      "step": 520
    },
    {
      "epoch": 0.07,
      "grad_norm": 8.361551284790039,
      "learning_rate": 0.00018664805178322122,
      "loss": 1.5406,
      "step": 530
    },
    {
      "epoch": 0.07,
      "grad_norm": 6.845181941986084,
      "learning_rate": 0.00018639421246351062,
      "loss": 1.3479,
      "step": 540
    },
    {
      "epoch": 0.07,
      "grad_norm": 3.800215721130371,
      "learning_rate": 0.00018614037314379996,
      "loss": 1.3391,
      "step": 550
    },
    {
      "epoch": 0.07,
      "grad_norm": 4.770440578460693,
      "learning_rate": 0.00018588653382408936,
      "loss": 1.5471,
      "step": 560
    },
    {
      "epoch": 0.07,
      "grad_norm": 4.295926094055176,
      "learning_rate": 0.00018563269450437876,
      "loss": 1.4625,
      "step": 570
    },
    {
      "epoch": 0.07,
      "grad_norm": 6.034209728240967,
      "learning_rate": 0.0001853788551846681,
      "loss": 1.6643,
      "step": 580
    },
    {
      "epoch": 0.07,
      "grad_norm": 6.172867774963379,
      "learning_rate": 0.0001851250158649575,
      "loss": 1.4661,
      "step": 590
    },
    {
      "epoch": 0.08,
      "grad_norm": 3.363875150680542,
      "learning_rate": 0.00018487117654524687,
      "loss": 1.7566,
      "step": 600
    },
    {
      "epoch": 0.08,
      "grad_norm": 4.408519744873047,
      "learning_rate": 0.00018461733722553624,
      "loss": 1.3682,
      "step": 610
    },
    {
      "epoch": 0.08,
      "grad_norm": 5.816562175750732,
      "learning_rate": 0.00018436349790582562,
      "loss": 1.5132,
      "step": 620
    },
    {
      "epoch": 0.08,
      "grad_norm": 4.7680511474609375,
      "learning_rate": 0.000184109658586115,
      "loss": 1.4986,
      "step": 630
    },
    {
      "epoch": 0.08,
      "grad_norm": 3.722787857055664,
      "learning_rate": 0.00018385581926640439,
      "loss": 1.5865,
      "step": 640
    },
    {
      "epoch": 0.08,
      "grad_norm": 4.309257507324219,
      "learning_rate": 0.00018360197994669376,
      "loss": 1.447,
      "step": 650
    },
    {
      "epoch": 0.08,
      "grad_norm": 6.13680362701416,
      "learning_rate": 0.00018334814062698313,
      "loss": 1.5371,
      "step": 660
    },
    {
      "epoch": 0.09,
      "grad_norm": 5.596528053283691,
      "learning_rate": 0.0001830943013072725,
      "loss": 1.3583,
      "step": 670
    },
    {
      "epoch": 0.09,
      "grad_norm": 3.154595375061035,
      "learning_rate": 0.00018284046198756187,
      "loss": 1.3877,
      "step": 680
    },
    {
      "epoch": 0.09,
      "grad_norm": 4.083518028259277,
      "learning_rate": 0.00018258662266785124,
      "loss": 1.3893,
      "step": 690
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.824198007583618,
      "learning_rate": 0.00018233278334814064,
      "loss": 1.3999,
      "step": 700
    },
    {
      "epoch": 0.09,
      "grad_norm": 3.8582041263580322,
      "learning_rate": 0.00018207894402843,
      "loss": 1.6739,
      "step": 710
    },
    {
      "epoch": 0.09,
      "grad_norm": 3.8914101123809814,
      "learning_rate": 0.00018182510470871938,
      "loss": 1.4088,
      "step": 720
    },
    {
      "epoch": 0.09,
      "grad_norm": 4.71256160736084,
      "learning_rate": 0.00018157126538900878,
      "loss": 1.5036,
      "step": 730
    },
    {
      "epoch": 0.09,
      "grad_norm": 9.82164192199707,
      "learning_rate": 0.00018131742606929813,
      "loss": 1.326,
      "step": 740
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.637434959411621,
      "learning_rate": 0.00018106358674958753,
      "loss": 1.6867,
      "step": 750
    },
    {
      "epoch": 0.1,
      "grad_norm": 3.403562307357788,
      "learning_rate": 0.0001808097474298769,
      "loss": 1.5771,
      "step": 760
    },
    {
      "epoch": 0.1,
      "grad_norm": 5.878627777099609,
      "learning_rate": 0.00018055590811016627,
      "loss": 1.4556,
      "step": 770
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.4782183170318604,
      "learning_rate": 0.00018030206879045567,
      "loss": 1.4542,
      "step": 780
    },
    {
      "epoch": 0.1,
      "grad_norm": 7.412893295288086,
      "learning_rate": 0.000180048229470745,
      "loss": 1.5842,
      "step": 790
    },
    {
      "epoch": 0.1,
      "grad_norm": 5.416374206542969,
      "learning_rate": 0.0001797943901510344,
      "loss": 1.59,
      "step": 800
    },
    {
      "epoch": 0.1,
      "grad_norm": 5.194374084472656,
      "learning_rate": 0.00017954055083132378,
      "loss": 1.5323,
      "step": 810
    },
    {
      "epoch": 0.1,
      "grad_norm": 6.608214855194092,
      "learning_rate": 0.00017928671151161315,
      "loss": 1.4972,
      "step": 820
    },
    {
      "epoch": 0.11,
      "grad_norm": 4.999664783477783,
      "learning_rate": 0.00017903287219190255,
      "loss": 1.431,
      "step": 830
    },
    {
      "epoch": 0.11,
      "grad_norm": 6.0013933181762695,
      "learning_rate": 0.0001787790328721919,
      "loss": 1.5291,
      "step": 840
    },
    {
      "epoch": 0.11,
      "grad_norm": 3.1262547969818115,
      "learning_rate": 0.0001785251935524813,
      "loss": 1.4791,
      "step": 850
    },
    {
      "epoch": 0.11,
      "grad_norm": 6.384070873260498,
      "learning_rate": 0.00017827135423277067,
      "loss": 1.4414,
      "step": 860
    },
    {
      "epoch": 0.11,
      "grad_norm": 3.6542327404022217,
      "learning_rate": 0.00017801751491306004,
      "loss": 1.3253,
      "step": 870
    },
    {
      "epoch": 0.11,
      "grad_norm": 3.7198784351348877,
      "learning_rate": 0.0001777636755933494,
      "loss": 1.4141,
      "step": 880
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.8080832958221436,
      "learning_rate": 0.0001775098362736388,
      "loss": 1.5188,
      "step": 890
    },
    {
      "epoch": 0.11,
      "grad_norm": 3.4163894653320312,
      "learning_rate": 0.00017725599695392818,
      "loss": 1.5428,
      "step": 900
    },
    {
      "epoch": 0.12,
      "grad_norm": 4.2565741539001465,
      "learning_rate": 0.00017700215763421755,
      "loss": 1.4166,
      "step": 910
    },
    {
      "epoch": 0.12,
      "grad_norm": 6.185779571533203,
      "learning_rate": 0.00017674831831450692,
      "loss": 1.5603,
      "step": 920
    },
    {
      "epoch": 0.12,
      "grad_norm": 4.085659980773926,
      "learning_rate": 0.0001764944789947963,
      "loss": 1.606,
      "step": 930
    },
    {
      "epoch": 0.12,
      "grad_norm": 3.3642678260803223,
      "learning_rate": 0.0001762406396750857,
      "loss": 1.4009,
      "step": 940
    },
    {
      "epoch": 0.12,
      "grad_norm": 7.7090888023376465,
      "learning_rate": 0.00017598680035537504,
      "loss": 1.4594,
      "step": 950
    },
    {
      "epoch": 0.12,
      "grad_norm": 5.385303497314453,
      "learning_rate": 0.00017573296103566444,
      "loss": 1.411,
      "step": 960
    },
    {
      "epoch": 0.12,
      "grad_norm": 4.388503551483154,
      "learning_rate": 0.0001754791217159538,
      "loss": 1.4307,
      "step": 970
    },
    {
      "epoch": 0.12,
      "grad_norm": 3.934281349182129,
      "learning_rate": 0.00017522528239624318,
      "loss": 1.482,
      "step": 980
    },
    {
      "epoch": 0.13,
      "grad_norm": 4.597839832305908,
      "learning_rate": 0.00017497144307653258,
      "loss": 1.2659,
      "step": 990
    },
    {
      "epoch": 0.13,
      "grad_norm": 3.523188829421997,
      "learning_rate": 0.00017471760375682192,
      "loss": 1.2961,
      "step": 1000
    },
    {
      "epoch": 0.13,
      "grad_norm": 5.863835334777832,
      "learning_rate": 0.00017446376443711132,
      "loss": 1.5165,
      "step": 1010
    },
    {
      "epoch": 0.13,
      "grad_norm": 7.626834392547607,
      "learning_rate": 0.0001742099251174007,
      "loss": 1.4884,
      "step": 1020
    },
    {
      "epoch": 0.13,
      "grad_norm": 5.056142330169678,
      "learning_rate": 0.00017395608579769006,
      "loss": 1.5042,
      "step": 1030
    },
    {
      "epoch": 0.13,
      "grad_norm": 4.070119380950928,
      "learning_rate": 0.00017370224647797946,
      "loss": 1.5338,
      "step": 1040
    },
    {
      "epoch": 0.13,
      "grad_norm": 6.956836700439453,
      "learning_rate": 0.00017344840715826883,
      "loss": 1.4678,
      "step": 1050
    },
    {
      "epoch": 0.13,
      "grad_norm": 3.3891990184783936,
      "learning_rate": 0.0001731945678385582,
      "loss": 1.5315,
      "step": 1060
    },
    {
      "epoch": 0.14,
      "grad_norm": 4.29390811920166,
      "learning_rate": 0.00017294072851884758,
      "loss": 1.4568,
      "step": 1070
    },
    {
      "epoch": 0.14,
      "grad_norm": 4.0545148849487305,
      "learning_rate": 0.00017268688919913695,
      "loss": 1.4197,
      "step": 1080
    },
    {
      "epoch": 0.14,
      "grad_norm": 4.776385307312012,
      "learning_rate": 0.00017243304987942632,
      "loss": 1.6241,
      "step": 1090
    },
    {
      "epoch": 0.14,
      "grad_norm": 4.587398529052734,
      "learning_rate": 0.00017217921055971572,
      "loss": 1.4472,
      "step": 1100
    },
    {
      "epoch": 0.14,
      "grad_norm": 7.8266072273254395,
      "learning_rate": 0.0001719253712400051,
      "loss": 1.6127,
      "step": 1110
    },
    {
      "epoch": 0.14,
      "grad_norm": 5.040794849395752,
      "learning_rate": 0.00017167153192029446,
      "loss": 1.7003,
      "step": 1120
    },
    {
      "epoch": 0.14,
      "grad_norm": 3.610352039337158,
      "learning_rate": 0.00017141769260058383,
      "loss": 1.4182,
      "step": 1130
    },
    {
      "epoch": 0.14,
      "grad_norm": 7.410372734069824,
      "learning_rate": 0.0001711638532808732,
      "loss": 1.5344,
      "step": 1140
    },
    {
      "epoch": 0.15,
      "grad_norm": 4.439311981201172,
      "learning_rate": 0.0001709100139611626,
      "loss": 1.5493,
      "step": 1150
    },
    {
      "epoch": 0.15,
      "grad_norm": 9.58899211883545,
      "learning_rate": 0.00017065617464145195,
      "loss": 1.6507,
      "step": 1160
    },
    {
      "epoch": 0.15,
      "grad_norm": 8.967304229736328,
      "learning_rate": 0.00017040233532174135,
      "loss": 1.4584,
      "step": 1170
    },
    {
      "epoch": 0.15,
      "grad_norm": 3.4903762340545654,
      "learning_rate": 0.00017014849600203075,
      "loss": 1.3597,
      "step": 1180
    },
    {
      "epoch": 0.15,
      "grad_norm": 3.5598580837249756,
      "learning_rate": 0.0001698946566823201,
      "loss": 1.4441,
      "step": 1190
    },
    {
      "epoch": 0.15,
      "grad_norm": 3.9957315921783447,
      "learning_rate": 0.0001696408173626095,
      "loss": 1.4273,
      "step": 1200
    },
    {
      "epoch": 0.15,
      "grad_norm": 3.939643144607544,
      "learning_rate": 0.00016938697804289886,
      "loss": 1.5078,
      "step": 1210
    },
    {
      "epoch": 0.15,
      "grad_norm": 9.161504745483398,
      "learning_rate": 0.00016913313872318823,
      "loss": 1.5617,
      "step": 1220
    },
    {
      "epoch": 0.16,
      "grad_norm": 4.531093120574951,
      "learning_rate": 0.0001688792994034776,
      "loss": 1.5941,
      "step": 1230
    },
    {
      "epoch": 0.16,
      "grad_norm": 5.0270867347717285,
      "learning_rate": 0.00016862546008376698,
      "loss": 1.5385,
      "step": 1240
    },
    {
      "epoch": 0.16,
      "grad_norm": 4.275627136230469,
      "learning_rate": 0.00016837162076405637,
      "loss": 1.285,
      "step": 1250
    },
    {
      "epoch": 0.16,
      "grad_norm": 4.8880228996276855,
      "learning_rate": 0.00016811778144434575,
      "loss": 1.5611,
      "step": 1260
    },
    {
      "epoch": 0.16,
      "grad_norm": 5.100536346435547,
      "learning_rate": 0.00016786394212463512,
      "loss": 1.5617,
      "step": 1270
    },
    {
      "epoch": 0.16,
      "grad_norm": 23.304752349853516,
      "learning_rate": 0.0001676101028049245,
      "loss": 1.4756,
      "step": 1280
    },
    {
      "epoch": 0.16,
      "grad_norm": 5.124148368835449,
      "learning_rate": 0.00016735626348521386,
      "loss": 1.3451,
      "step": 1290
    },
    {
      "epoch": 0.16,
      "grad_norm": 5.557555198669434,
      "learning_rate": 0.0001671278080974743,
      "loss": 1.5492,
      "step": 1300
    },
    {
      "epoch": 0.17,
      "grad_norm": 3.606506586074829,
      "learning_rate": 0.00016687396877776368,
      "loss": 1.5557,
      "step": 1310
    },
    {
      "epoch": 0.17,
      "grad_norm": 4.513331890106201,
      "learning_rate": 0.00016662012945805306,
      "loss": 1.4951,
      "step": 1320
    },
    {
      "epoch": 0.17,
      "grad_norm": 5.672008991241455,
      "learning_rate": 0.00016636629013834243,
      "loss": 1.2921,
      "step": 1330
    },
    {
      "epoch": 0.17,
      "grad_norm": 4.550190448760986,
      "learning_rate": 0.0001661124508186318,
      "loss": 1.5481,
      "step": 1340
    },
    {
      "epoch": 0.17,
      "grad_norm": 4.686933517456055,
      "learning_rate": 0.0001658586114989212,
      "loss": 1.506,
      "step": 1350
    },
    {
      "epoch": 0.17,
      "grad_norm": 7.49794340133667,
      "learning_rate": 0.00016560477217921057,
      "loss": 1.4779,
      "step": 1360
    },
    {
      "epoch": 0.17,
      "grad_norm": 4.201563835144043,
      "learning_rate": 0.00016535093285949994,
      "loss": 1.5383,
      "step": 1370
    },
    {
      "epoch": 0.18,
      "grad_norm": 9.960715293884277,
      "learning_rate": 0.00016509709353978934,
      "loss": 1.5772,
      "step": 1380
    },
    {
      "epoch": 0.18,
      "grad_norm": 5.133706092834473,
      "learning_rate": 0.00016484325422007868,
      "loss": 1.3183,
      "step": 1390
    },
    {
      "epoch": 0.18,
      "grad_norm": 5.4035773277282715,
      "learning_rate": 0.00016458941490036808,
      "loss": 1.4124,
      "step": 1400
    },
    {
      "epoch": 0.18,
      "grad_norm": 6.124221324920654,
      "learning_rate": 0.00016433557558065745,
      "loss": 1.5149,
      "step": 1410
    },
    {
      "epoch": 0.18,
      "grad_norm": 4.122192859649658,
      "learning_rate": 0.00016408173626094683,
      "loss": 1.6014,
      "step": 1420
    },
    {
      "epoch": 0.18,
      "grad_norm": 3.1865532398223877,
      "learning_rate": 0.00016382789694123622,
      "loss": 1.5726,
      "step": 1430
    },
    {
      "epoch": 0.18,
      "grad_norm": 5.528578758239746,
      "learning_rate": 0.00016357405762152557,
      "loss": 1.5795,
      "step": 1440
    },
    {
      "epoch": 0.18,
      "grad_norm": 3.988159656524658,
      "learning_rate": 0.00016332021830181497,
      "loss": 1.4276,
      "step": 1450
    },
    {
      "epoch": 0.19,
      "grad_norm": 4.501916885375977,
      "learning_rate": 0.00016306637898210434,
      "loss": 1.4012,
      "step": 1460
    },
    {
      "epoch": 0.19,
      "grad_norm": 9.026968955993652,
      "learning_rate": 0.0001628125396623937,
      "loss": 1.3626,
      "step": 1470
    },
    {
      "epoch": 0.19,
      "grad_norm": 3.1133110523223877,
      "learning_rate": 0.00016255870034268308,
      "loss": 1.4393,
      "step": 1480
    },
    {
      "epoch": 0.19,
      "grad_norm": 5.076137542724609,
      "learning_rate": 0.00016230486102297245,
      "loss": 1.6609,
      "step": 1490
    },
    {
      "epoch": 0.19,
      "grad_norm": 4.03191614151001,
      "learning_rate": 0.00016205102170326185,
      "loss": 1.5644,
      "step": 1500
    },
    {
      "epoch": 0.19,
      "grad_norm": 5.703763961791992,
      "learning_rate": 0.00016179718238355122,
      "loss": 1.3557,
      "step": 1510
    },
    {
      "epoch": 0.19,
      "grad_norm": 3.70987606048584,
      "learning_rate": 0.0001615433430638406,
      "loss": 1.5181,
      "step": 1520
    },
    {
      "epoch": 0.19,
      "grad_norm": 6.467290878295898,
      "learning_rate": 0.00016128950374412997,
      "loss": 1.5504,
      "step": 1530
    },
    {
      "epoch": 0.2,
      "grad_norm": 3.5181314945220947,
      "learning_rate": 0.00016103566442441937,
      "loss": 1.3038,
      "step": 1540
    },
    {
      "epoch": 0.2,
      "grad_norm": 6.012288570404053,
      "learning_rate": 0.0001607818251047087,
      "loss": 1.4757,
      "step": 1550
    },
    {
      "epoch": 0.2,
      "grad_norm": 4.331679344177246,
      "learning_rate": 0.0001605279857849981,
      "loss": 1.4612,
      "step": 1560
    },
    {
      "epoch": 0.2,
      "grad_norm": 8.842281341552734,
      "learning_rate": 0.00016027414646528748,
      "loss": 1.577,
      "step": 1570
    },
    {
      "epoch": 0.2,
      "grad_norm": 4.705521106719971,
      "learning_rate": 0.00016002030714557685,
      "loss": 1.554,
      "step": 1580
    },
    {
      "epoch": 0.2,
      "grad_norm": 3.0493874549865723,
      "learning_rate": 0.00015976646782586625,
      "loss": 1.3657,
      "step": 1590
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.674466371536255,
      "learning_rate": 0.0001595126285061556,
      "loss": 1.5637,
      "step": 1600
    },
    {
      "epoch": 0.2,
      "grad_norm": 8.080204010009766,
      "learning_rate": 0.000159258789186445,
      "loss": 1.3741,
      "step": 1610
    },
    {
      "epoch": 0.21,
      "grad_norm": 5.25952672958374,
      "learning_rate": 0.00015900494986673436,
      "loss": 1.5021,
      "step": 1620
    },
    {
      "epoch": 0.21,
      "grad_norm": 5.870262145996094,
      "learning_rate": 0.00015875111054702374,
      "loss": 1.5805,
      "step": 1630
    },
    {
      "epoch": 0.21,
      "grad_norm": 4.027941703796387,
      "learning_rate": 0.00015849727122731313,
      "loss": 1.5128,
      "step": 1640
    },
    {
      "epoch": 0.21,
      "grad_norm": 4.342813968658447,
      "learning_rate": 0.00015824343190760248,
      "loss": 1.4736,
      "step": 1650
    },
    {
      "epoch": 0.21,
      "grad_norm": 3.5686216354370117,
      "learning_rate": 0.00015798959258789188,
      "loss": 1.4956,
      "step": 1660
    },
    {
      "epoch": 0.21,
      "grad_norm": 5.914581775665283,
      "learning_rate": 0.00015773575326818125,
      "loss": 1.411,
      "step": 1670
    },
    {
      "epoch": 0.21,
      "grad_norm": 5.309281826019287,
      "learning_rate": 0.00015748191394847062,
      "loss": 1.4832,
      "step": 1680
    },
    {
      "epoch": 0.21,
      "grad_norm": 3.4890031814575195,
      "learning_rate": 0.00015722807462876,
      "loss": 1.2773,
      "step": 1690
    },
    {
      "epoch": 0.22,
      "grad_norm": 5.693027973175049,
      "learning_rate": 0.0001569742353090494,
      "loss": 1.6352,
      "step": 1700
    },
    {
      "epoch": 0.22,
      "grad_norm": 4.520772933959961,
      "learning_rate": 0.00015672039598933876,
      "loss": 1.4773,
      "step": 1710
    },
    {
      "epoch": 0.22,
      "grad_norm": 6.761288642883301,
      "learning_rate": 0.00015646655666962813,
      "loss": 1.4992,
      "step": 1720
    },
    {
      "epoch": 0.22,
      "grad_norm": 3.8994548320770264,
      "learning_rate": 0.0001562127173499175,
      "loss": 1.6389,
      "step": 1730
    },
    {
      "epoch": 0.22,
      "grad_norm": 3.7484865188598633,
      "learning_rate": 0.00015595887803020688,
      "loss": 1.5028,
      "step": 1740
    },
    {
      "epoch": 0.22,
      "grad_norm": 4.2258124351501465,
      "learning_rate": 0.00015570503871049628,
      "loss": 1.4762,
      "step": 1750
    },
    {
      "epoch": 0.22,
      "grad_norm": 5.108799457550049,
      "learning_rate": 0.00015545119939078565,
      "loss": 1.4086,
      "step": 1760
    },
    {
      "epoch": 0.22,
      "grad_norm": 4.799554824829102,
      "learning_rate": 0.00015519736007107502,
      "loss": 1.3934,
      "step": 1770
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.7901532649993896,
      "learning_rate": 0.0001549435207513644,
      "loss": 1.4086,
      "step": 1780
    },
    {
      "epoch": 0.23,
      "grad_norm": 4.094459533691406,
      "learning_rate": 0.00015468968143165376,
      "loss": 1.4332,
      "step": 1790
    },
    {
      "epoch": 0.23,
      "grad_norm": 6.220344543457031,
      "learning_rate": 0.00015443584211194316,
      "loss": 1.584,
      "step": 1800
    },
    {
      "epoch": 0.23,
      "grad_norm": 4.995721340179443,
      "learning_rate": 0.0001541820027922325,
      "loss": 1.4071,
      "step": 1810
    },
    {
      "epoch": 0.23,
      "grad_norm": 10.597603797912598,
      "learning_rate": 0.0001539281634725219,
      "loss": 1.636,
      "step": 1820
    },
    {
      "epoch": 0.23,
      "grad_norm": 5.023432731628418,
      "learning_rate": 0.0001536743241528113,
      "loss": 1.488,
      "step": 1830
    },
    {
      "epoch": 0.23,
      "grad_norm": 10.484354972839355,
      "learning_rate": 0.00015342048483310065,
      "loss": 1.4466,
      "step": 1840
    },
    {
      "epoch": 0.23,
      "grad_norm": 6.733252048492432,
      "learning_rate": 0.00015316664551339005,
      "loss": 1.6017,
      "step": 1850
    },
    {
      "epoch": 0.24,
      "grad_norm": 3.7754178047180176,
      "learning_rate": 0.0001529128061936794,
      "loss": 1.4875,
      "step": 1860
    },
    {
      "epoch": 0.24,
      "grad_norm": 3.965226173400879,
      "learning_rate": 0.0001526589668739688,
      "loss": 1.6461,
      "step": 1870
    },
    {
      "epoch": 0.24,
      "grad_norm": 4.939765453338623,
      "learning_rate": 0.00015240512755425816,
      "loss": 1.4526,
      "step": 1880
    },
    {
      "epoch": 0.24,
      "grad_norm": 4.563659191131592,
      "learning_rate": 0.00015215128823454753,
      "loss": 1.466,
      "step": 1890
    },
    {
      "epoch": 0.24,
      "grad_norm": 8.449594497680664,
      "learning_rate": 0.00015189744891483693,
      "loss": 1.3491,
      "step": 1900
    },
    {
      "epoch": 0.24,
      "grad_norm": 3.4007203578948975,
      "learning_rate": 0.0001516436095951263,
      "loss": 1.5346,
      "step": 1910
    },
    {
      "epoch": 0.24,
      "grad_norm": 5.04263973236084,
      "learning_rate": 0.00015138977027541567,
      "loss": 1.5466,
      "step": 1920
    },
    {
      "epoch": 0.24,
      "grad_norm": 14.146698951721191,
      "learning_rate": 0.00015113593095570504,
      "loss": 1.3948,
      "step": 1930
    },
    {
      "epoch": 0.25,
      "grad_norm": 6.305365562438965,
      "learning_rate": 0.00015088209163599442,
      "loss": 1.5394,
      "step": 1940
    },
    {
      "epoch": 0.25,
      "grad_norm": 4.721161365509033,
      "learning_rate": 0.0001506282523162838,
      "loss": 1.4579,
      "step": 1950
    },
    {
      "epoch": 0.25,
      "grad_norm": 3.228506088256836,
      "learning_rate": 0.00015037441299657319,
      "loss": 1.4948,
      "step": 1960
    },
    {
      "epoch": 0.25,
      "grad_norm": 4.890807628631592,
      "learning_rate": 0.00015012057367686256,
      "loss": 1.3115,
      "step": 1970
    },
    {
      "epoch": 0.25,
      "grad_norm": 3.332435369491577,
      "learning_rate": 0.00014986673435715193,
      "loss": 1.5194,
      "step": 1980
    },
    {
      "epoch": 0.25,
      "grad_norm": 4.501515865325928,
      "learning_rate": 0.0001496128950374413,
      "loss": 1.5524,
      "step": 1990
    },
    {
      "epoch": 0.25,
      "grad_norm": 6.25795316696167,
      "learning_rate": 0.00014935905571773067,
      "loss": 1.3852,
      "step": 2000
    },
    {
      "epoch": 0.26,
      "grad_norm": 6.067669868469238,
      "learning_rate": 0.00014910521639802007,
      "loss": 1.4815,
      "step": 2010
    },
    {
      "epoch": 0.26,
      "grad_norm": 3.691495180130005,
      "learning_rate": 0.00014885137707830942,
      "loss": 1.5034,
      "step": 2020
    },
    {
      "epoch": 0.26,
      "grad_norm": 3.804936170578003,
      "learning_rate": 0.00014859753775859881,
      "loss": 1.3261,
      "step": 2030
    },
    {
      "epoch": 0.26,
      "grad_norm": 5.190098285675049,
      "learning_rate": 0.0001483436984388882,
      "loss": 1.2719,
      "step": 2040
    },
    {
      "epoch": 0.26,
      "grad_norm": 4.216224193572998,
      "learning_rate": 0.00014808985911917756,
      "loss": 1.3612,
      "step": 2050
    },
    {
      "epoch": 0.26,
      "grad_norm": 3.6711063385009766,
      "learning_rate": 0.00014783601979946696,
      "loss": 1.4103,
      "step": 2060
    },
    {
      "epoch": 0.26,
      "grad_norm": 15.006584167480469,
      "learning_rate": 0.00014758218047975633,
      "loss": 1.5132,
      "step": 2070
    },
    {
      "epoch": 0.26,
      "grad_norm": 6.510122299194336,
      "learning_rate": 0.0001473283411600457,
      "loss": 1.4581,
      "step": 2080
    },
    {
      "epoch": 0.27,
      "grad_norm": 5.347665786743164,
      "learning_rate": 0.00014707450184033507,
      "loss": 1.4844,
      "step": 2090
    },
    {
      "epoch": 0.27,
      "grad_norm": 4.118561744689941,
      "learning_rate": 0.00014682066252062444,
      "loss": 1.56,
      "step": 2100
    },
    {
      "epoch": 0.27,
      "grad_norm": 4.102832317352295,
      "learning_rate": 0.00014656682320091384,
      "loss": 1.3607,
      "step": 2110
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.9339611530303955,
      "learning_rate": 0.0001463129838812032,
      "loss": 1.5858,
      "step": 2120
    },
    {
      "epoch": 0.27,
      "grad_norm": 7.196298122406006,
      "learning_rate": 0.00014605914456149258,
      "loss": 1.4873,
      "step": 2130
    },
    {
      "epoch": 0.27,
      "grad_norm": 5.111709117889404,
      "learning_rate": 0.00014580530524178195,
      "loss": 1.6375,
      "step": 2140
    },
    {
      "epoch": 0.27,
      "grad_norm": 5.296072006225586,
      "learning_rate": 0.00014555146592207133,
      "loss": 1.5421,
      "step": 2150
    },
    {
      "epoch": 0.27,
      "grad_norm": 3.2750213146209717,
      "learning_rate": 0.0001452976266023607,
      "loss": 1.4959,
      "step": 2160
    },
    {
      "epoch": 0.28,
      "grad_norm": 5.943974494934082,
      "learning_rate": 0.0001450437872826501,
      "loss": 1.6727,
      "step": 2170
    },
    {
      "epoch": 0.28,
      "grad_norm": 3.098442792892456,
      "learning_rate": 0.00014478994796293947,
      "loss": 1.3569,
      "step": 2180
    },
    {
      "epoch": 0.28,
      "grad_norm": 8.382002830505371,
      "learning_rate": 0.00014453610864322884,
      "loss": 1.4072,
      "step": 2190
    },
    {
      "epoch": 0.28,
      "grad_norm": 4.655130863189697,
      "learning_rate": 0.00014428226932351824,
      "loss": 1.654,
      "step": 2200
    },
    {
      "epoch": 0.28,
      "grad_norm": 5.281121730804443,
      "learning_rate": 0.00014402843000380758,
      "loss": 1.5518,
      "step": 2210
    },
    {
      "epoch": 0.28,
      "grad_norm": 4.878538608551025,
      "learning_rate": 0.00014377459068409698,
      "loss": 1.2574,
      "step": 2220
    },
    {
      "epoch": 0.28,
      "grad_norm": 8.087018966674805,
      "learning_rate": 0.00014352075136438635,
      "loss": 1.443,
      "step": 2230
    },
    {
      "epoch": 0.28,
      "grad_norm": 4.725767612457275,
      "learning_rate": 0.00014326691204467572,
      "loss": 1.5348,
      "step": 2240
    },
    {
      "epoch": 0.29,
      "grad_norm": 8.217093467712402,
      "learning_rate": 0.00014301307272496512,
      "loss": 1.5901,
      "step": 2250
    },
    {
      "epoch": 0.29,
      "grad_norm": 8.990093231201172,
      "learning_rate": 0.00014278461733722555,
      "loss": 1.58,
      "step": 2260
    },
    {
      "epoch": 0.29,
      "grad_norm": 7.8387298583984375,
      "learning_rate": 0.00014253077801751492,
      "loss": 1.5542,
      "step": 2270
    },
    {
      "epoch": 0.29,
      "grad_norm": 5.107207775115967,
      "learning_rate": 0.0001422769386978043,
      "loss": 1.4226,
      "step": 2280
    },
    {
      "epoch": 0.29,
      "grad_norm": 5.600339412689209,
      "learning_rate": 0.0001420230993780937,
      "loss": 1.3127,
      "step": 2290
    },
    {
      "epoch": 0.29,
      "grad_norm": 4.561391353607178,
      "learning_rate": 0.00014176926005838304,
      "loss": 1.3984,
      "step": 2300
    },
    {
      "epoch": 0.29,
      "grad_norm": 5.320052623748779,
      "learning_rate": 0.00014151542073867243,
      "loss": 1.4687,
      "step": 2310
    },
    {
      "epoch": 0.29,
      "grad_norm": 3.8054981231689453,
      "learning_rate": 0.0001412615814189618,
      "loss": 1.6585,
      "step": 2320
    },
    {
      "epoch": 0.3,
      "grad_norm": 11.154077529907227,
      "learning_rate": 0.00014100774209925118,
      "loss": 1.5962,
      "step": 2330
    },
    {
      "epoch": 0.3,
      "grad_norm": 6.827926158905029,
      "learning_rate": 0.00014075390277954055,
      "loss": 1.6737,
      "step": 2340
    },
    {
      "epoch": 0.3,
      "grad_norm": 3.4495010375976562,
      "learning_rate": 0.00014050006345982992,
      "loss": 1.5108,
      "step": 2350
    },
    {
      "epoch": 0.3,
      "grad_norm": 4.327031135559082,
      "learning_rate": 0.00014024622414011932,
      "loss": 1.5881,
      "step": 2360
    },
    {
      "epoch": 0.3,
      "grad_norm": 9.64786148071289,
      "learning_rate": 0.0001399923848204087,
      "loss": 1.4525,
      "step": 2370
    },
    {
      "epoch": 0.3,
      "grad_norm": 4.9729485511779785,
      "learning_rate": 0.00013973854550069806,
      "loss": 1.593,
      "step": 2380
    },
    {
      "epoch": 0.3,
      "grad_norm": 9.44579792022705,
      "learning_rate": 0.00013948470618098743,
      "loss": 1.3868,
      "step": 2390
    },
    {
      "epoch": 0.3,
      "grad_norm": 4.073144435882568,
      "learning_rate": 0.00013923086686127683,
      "loss": 1.4841,
      "step": 2400
    },
    {
      "epoch": 0.31,
      "grad_norm": 6.975934028625488,
      "learning_rate": 0.00013897702754156618,
      "loss": 1.6156,
      "step": 2410
    },
    {
      "epoch": 0.31,
      "grad_norm": 7.632857799530029,
      "learning_rate": 0.00013872318822185558,
      "loss": 1.5619,
      "step": 2420
    },
    {
      "epoch": 0.31,
      "grad_norm": 3.589820384979248,
      "learning_rate": 0.00013846934890214495,
      "loss": 1.4038,
      "step": 2430
    },
    {
      "epoch": 0.31,
      "grad_norm": 3.807976245880127,
      "learning_rate": 0.00013821550958243432,
      "loss": 1.4308,
      "step": 2440
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.51049542427063,
      "learning_rate": 0.00013796167026272372,
      "loss": 1.4802,
      "step": 2450
    },
    {
      "epoch": 0.31,
      "grad_norm": 3.623755693435669,
      "learning_rate": 0.00013770783094301306,
      "loss": 1.4462,
      "step": 2460
    },
    {
      "epoch": 0.31,
      "grad_norm": 10.155773162841797,
      "learning_rate": 0.00013745399162330246,
      "loss": 1.5658,
      "step": 2470
    },
    {
      "epoch": 0.31,
      "grad_norm": 7.793664455413818,
      "learning_rate": 0.00013720015230359183,
      "loss": 1.5934,
      "step": 2480
    },
    {
      "epoch": 0.32,
      "grad_norm": 3.887890577316284,
      "learning_rate": 0.0001369463129838812,
      "loss": 1.3555,
      "step": 2490
    },
    {
      "epoch": 0.32,
      "grad_norm": 5.319519996643066,
      "learning_rate": 0.0001366924736641706,
      "loss": 1.7118,
      "step": 2500
    },
    {
      "epoch": 0.32,
      "grad_norm": 4.183501720428467,
      "learning_rate": 0.00013643863434445995,
      "loss": 1.3623,
      "step": 2510
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.8845789432525635,
      "learning_rate": 0.00013618479502474934,
      "loss": 1.4796,
      "step": 2520
    },
    {
      "epoch": 0.32,
      "grad_norm": 6.57379674911499,
      "learning_rate": 0.00013593095570503872,
      "loss": 1.4418,
      "step": 2530
    },
    {
      "epoch": 0.32,
      "grad_norm": 5.692047595977783,
      "learning_rate": 0.0001356771163853281,
      "loss": 1.4873,
      "step": 2540
    },
    {
      "epoch": 0.32,
      "grad_norm": 4.1973557472229,
      "learning_rate": 0.00013542327706561746,
      "loss": 1.3107,
      "step": 2550
    },
    {
      "epoch": 0.32,
      "grad_norm": 3.827798843383789,
      "learning_rate": 0.00013516943774590686,
      "loss": 1.5474,
      "step": 2560
    },
    {
      "epoch": 0.33,
      "grad_norm": 3.6743836402893066,
      "learning_rate": 0.00013491559842619623,
      "loss": 1.5591,
      "step": 2570
    },
    {
      "epoch": 0.33,
      "grad_norm": 5.377201557159424,
      "learning_rate": 0.0001346617591064856,
      "loss": 1.6358,
      "step": 2580
    },
    {
      "epoch": 0.33,
      "grad_norm": 3.723560094833374,
      "learning_rate": 0.00013440791978677497,
      "loss": 1.4243,
      "step": 2590
    },
    {
      "epoch": 0.33,
      "grad_norm": 5.725024223327637,
      "learning_rate": 0.00013415408046706434,
      "loss": 1.6427,
      "step": 2600
    },
    {
      "epoch": 0.33,
      "grad_norm": 3.5796217918395996,
      "learning_rate": 0.00013390024114735374,
      "loss": 1.4852,
      "step": 2610
    },
    {
      "epoch": 0.33,
      "grad_norm": 11.270773887634277,
      "learning_rate": 0.0001336464018276431,
      "loss": 1.49,
      "step": 2620
    },
    {
      "epoch": 0.33,
      "grad_norm": 3.2674906253814697,
      "learning_rate": 0.00013339256250793249,
      "loss": 1.4951,
      "step": 2630
    },
    {
      "epoch": 0.34,
      "grad_norm": 5.633563995361328,
      "learning_rate": 0.00013313872318822186,
      "loss": 1.4405,
      "step": 2640
    },
    {
      "epoch": 0.34,
      "grad_norm": 3.429823160171509,
      "learning_rate": 0.00013288488386851123,
      "loss": 1.4459,
      "step": 2650
    },
    {
      "epoch": 0.34,
      "grad_norm": 3.8567659854888916,
      "learning_rate": 0.00013263104454880063,
      "loss": 1.425,
      "step": 2660
    },
    {
      "epoch": 0.34,
      "grad_norm": 3.3597660064697266,
      "learning_rate": 0.00013237720522908997,
      "loss": 1.4347,
      "step": 2670
    },
    {
      "epoch": 0.34,
      "grad_norm": 7.771633625030518,
      "learning_rate": 0.00013212336590937937,
      "loss": 1.477,
      "step": 2680
    },
    {
      "epoch": 0.34,
      "grad_norm": 5.473611354827881,
      "learning_rate": 0.00013186952658966877,
      "loss": 1.5892,
      "step": 2690
    },
    {
      "epoch": 0.34,
      "grad_norm": 5.6672797203063965,
      "learning_rate": 0.0001316156872699581,
      "loss": 1.5021,
      "step": 2700
    },
    {
      "epoch": 0.34,
      "grad_norm": 5.013725280761719,
      "learning_rate": 0.0001313618479502475,
      "loss": 1.4638,
      "step": 2710
    },
    {
      "epoch": 0.35,
      "grad_norm": 6.852114677429199,
      "learning_rate": 0.00013110800863053688,
      "loss": 1.5364,
      "step": 2720
    },
    {
      "epoch": 0.35,
      "grad_norm": 3.601663589477539,
      "learning_rate": 0.00013085416931082625,
      "loss": 1.5309,
      "step": 2730
    },
    {
      "epoch": 0.35,
      "grad_norm": 11.408562660217285,
      "learning_rate": 0.00013060032999111563,
      "loss": 1.4476,
      "step": 2740
    },
    {
      "epoch": 0.35,
      "grad_norm": 4.924135684967041,
      "learning_rate": 0.000130346490671405,
      "loss": 1.454,
      "step": 2750
    },
    {
      "epoch": 0.35,
      "grad_norm": 4.383367538452148,
      "learning_rate": 0.0001300926513516944,
      "loss": 1.5136,
      "step": 2760
    },
    {
      "epoch": 0.35,
      "grad_norm": 6.79773473739624,
      "learning_rate": 0.00012983881203198377,
      "loss": 1.4988,
      "step": 2770
    },
    {
      "epoch": 0.35,
      "grad_norm": 5.071610927581787,
      "learning_rate": 0.00012958497271227314,
      "loss": 1.3682,
      "step": 2780
    },
    {
      "epoch": 0.35,
      "grad_norm": 5.598926544189453,
      "learning_rate": 0.0001293311333925625,
      "loss": 1.375,
      "step": 2790
    },
    {
      "epoch": 0.36,
      "grad_norm": 3.0531375408172607,
      "learning_rate": 0.00012907729407285188,
      "loss": 1.5324,
      "step": 2800
    },
    {
      "epoch": 0.36,
      "grad_norm": 8.001372337341309,
      "learning_rate": 0.00012882345475314125,
      "loss": 1.409,
      "step": 2810
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.6196787357330322,
      "learning_rate": 0.00012856961543343065,
      "loss": 1.4324,
      "step": 2820
    },
    {
      "epoch": 0.36,
      "grad_norm": 8.672870635986328,
      "learning_rate": 0.00012831577611372002,
      "loss": 1.4736,
      "step": 2830
    },
    {
      "epoch": 0.36,
      "grad_norm": 4.6525044441223145,
      "learning_rate": 0.0001280619367940094,
      "loss": 1.5121,
      "step": 2840
    },
    {
      "epoch": 0.36,
      "grad_norm": 3.952099323272705,
      "learning_rate": 0.0001278080974742988,
      "loss": 1.375,
      "step": 2850
    },
    {
      "epoch": 0.36,
      "grad_norm": 3.8985755443573,
      "learning_rate": 0.00012755425815458814,
      "loss": 1.4425,
      "step": 2860
    },
    {
      "epoch": 0.36,
      "grad_norm": 3.8957111835479736,
      "learning_rate": 0.00012730041883487754,
      "loss": 1.417,
      "step": 2870
    },
    {
      "epoch": 0.37,
      "grad_norm": 6.9895501136779785,
      "learning_rate": 0.0001270465795151669,
      "loss": 1.4855,
      "step": 2880
    },
    {
      "epoch": 0.37,
      "grad_norm": 5.71403694152832,
      "learning_rate": 0.00012679274019545628,
      "loss": 1.4348,
      "step": 2890
    },
    {
      "epoch": 0.37,
      "grad_norm": 4.226337909698486,
      "learning_rate": 0.00012653890087574568,
      "loss": 1.5197,
      "step": 2900
    },
    {
      "epoch": 0.37,
      "grad_norm": 4.219170570373535,
      "learning_rate": 0.00012628506155603502,
      "loss": 1.53,
      "step": 2910
    },
    {
      "epoch": 0.37,
      "grad_norm": 10.401673316955566,
      "learning_rate": 0.00012603122223632442,
      "loss": 1.4599,
      "step": 2920
    },
    {
      "epoch": 0.37,
      "grad_norm": 15.098933219909668,
      "learning_rate": 0.0001257773829166138,
      "loss": 1.4765,
      "step": 2930
    },
    {
      "epoch": 0.37,
      "grad_norm": 4.369052410125732,
      "learning_rate": 0.00012552354359690317,
      "loss": 1.4558,
      "step": 2940
    },
    {
      "epoch": 0.37,
      "grad_norm": 5.559057712554932,
      "learning_rate": 0.00012526970427719254,
      "loss": 1.2623,
      "step": 2950
    },
    {
      "epoch": 0.38,
      "grad_norm": 4.048995018005371,
      "learning_rate": 0.0001250158649574819,
      "loss": 1.4807,
      "step": 2960
    },
    {
      "epoch": 0.38,
      "grad_norm": 3.319028377532959,
      "learning_rate": 0.0001247620256377713,
      "loss": 1.3888,
      "step": 2970
    },
    {
      "epoch": 0.38,
      "grad_norm": 4.47987699508667,
      "learning_rate": 0.00012450818631806068,
      "loss": 1.5345,
      "step": 2980
    },
    {
      "epoch": 0.38,
      "grad_norm": 5.017792701721191,
      "learning_rate": 0.0001242797309303211,
      "loss": 1.4319,
      "step": 2990
    },
    {
      "epoch": 0.38,
      "grad_norm": 3.72971248626709,
      "learning_rate": 0.00012402589161061048,
      "loss": 1.1791,
      "step": 3000
    },
    {
      "epoch": 0.38,
      "grad_norm": 6.090186595916748,
      "learning_rate": 0.00012377205229089987,
      "loss": 1.5173,
      "step": 3010
    },
    {
      "epoch": 0.38,
      "grad_norm": 4.582968235015869,
      "learning_rate": 0.00012351821297118925,
      "loss": 1.6133,
      "step": 3020
    },
    {
      "epoch": 0.38,
      "grad_norm": 5.822057247161865,
      "learning_rate": 0.00012326437365147862,
      "loss": 1.6302,
      "step": 3030
    },
    {
      "epoch": 0.39,
      "grad_norm": 4.8660383224487305,
      "learning_rate": 0.000123010534331768,
      "loss": 1.386,
      "step": 3040
    },
    {
      "epoch": 0.39,
      "grad_norm": 3.909032106399536,
      "learning_rate": 0.0001227566950120574,
      "loss": 1.5186,
      "step": 3050
    },
    {
      "epoch": 0.39,
      "grad_norm": 5.285140037536621,
      "learning_rate": 0.00012250285569234673,
      "loss": 1.495,
      "step": 3060
    },
    {
      "epoch": 0.39,
      "grad_norm": 6.649825096130371,
      "learning_rate": 0.00012224901637263613,
      "loss": 1.5488,
      "step": 3070
    },
    {
      "epoch": 0.39,
      "grad_norm": 4.170200824737549,
      "learning_rate": 0.00012199517705292552,
      "loss": 1.5735,
      "step": 3080
    },
    {
      "epoch": 0.39,
      "grad_norm": 6.212615489959717,
      "learning_rate": 0.00012174133773321487,
      "loss": 1.6373,
      "step": 3090
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.9543206691741943,
      "learning_rate": 0.00012148749841350426,
      "loss": 1.3894,
      "step": 3100
    },
    {
      "epoch": 0.39,
      "grad_norm": 8.425219535827637,
      "learning_rate": 0.00012123365909379363,
      "loss": 1.4571,
      "step": 3110
    },
    {
      "epoch": 0.4,
      "grad_norm": 6.932032108306885,
      "learning_rate": 0.00012097981977408302,
      "loss": 1.3609,
      "step": 3120
    },
    {
      "epoch": 0.4,
      "grad_norm": 5.471286773681641,
      "learning_rate": 0.00012072598045437237,
      "loss": 1.5502,
      "step": 3130
    },
    {
      "epoch": 0.4,
      "grad_norm": 5.843173503875732,
      "learning_rate": 0.00012047214113466176,
      "loss": 1.3739,
      "step": 3140
    },
    {
      "epoch": 0.4,
      "grad_norm": 5.788458347320557,
      "learning_rate": 0.00012021830181495116,
      "loss": 1.4635,
      "step": 3150
    },
    {
      "epoch": 0.4,
      "grad_norm": 6.056306838989258,
      "learning_rate": 0.00011996446249524052,
      "loss": 1.3682,
      "step": 3160
    },
    {
      "epoch": 0.4,
      "grad_norm": 4.462047100067139,
      "learning_rate": 0.0001197106231755299,
      "loss": 1.6021,
      "step": 3170
    },
    {
      "epoch": 0.4,
      "grad_norm": 4.779072284698486,
      "learning_rate": 0.00011945678385581926,
      "loss": 1.5382,
      "step": 3180
    },
    {
      "epoch": 0.4,
      "grad_norm": 4.470580577850342,
      "learning_rate": 0.00011920294453610866,
      "loss": 1.3241,
      "step": 3190
    },
    {
      "epoch": 0.41,
      "grad_norm": 4.733761787414551,
      "learning_rate": 0.00011894910521639802,
      "loss": 1.4257,
      "step": 3200
    },
    {
      "epoch": 0.41,
      "grad_norm": 5.288991451263428,
      "learning_rate": 0.0001186952658966874,
      "loss": 1.6172,
      "step": 3210
    },
    {
      "epoch": 0.41,
      "grad_norm": 5.857954978942871,
      "learning_rate": 0.00011844142657697679,
      "loss": 1.6216,
      "step": 3220
    },
    {
      "epoch": 0.41,
      "grad_norm": 3.982593059539795,
      "learning_rate": 0.00011818758725726616,
      "loss": 1.4448,
      "step": 3230
    },
    {
      "epoch": 0.41,
      "grad_norm": 6.88903284072876,
      "learning_rate": 0.00011793374793755554,
      "loss": 1.2689,
      "step": 3240
    },
    {
      "epoch": 0.41,
      "grad_norm": 6.428385257720947,
      "learning_rate": 0.0001176799086178449,
      "loss": 1.3687,
      "step": 3250
    },
    {
      "epoch": 0.41,
      "grad_norm": 6.5771965980529785,
      "learning_rate": 0.00011742606929813429,
      "loss": 1.4869,
      "step": 3260
    },
    {
      "epoch": 0.42,
      "grad_norm": 6.134398937225342,
      "learning_rate": 0.00011717222997842366,
      "loss": 1.4901,
      "step": 3270
    },
    {
      "epoch": 0.42,
      "grad_norm": 5.7023749351501465,
      "learning_rate": 0.00011691839065871304,
      "loss": 1.4956,
      "step": 3280
    },
    {
      "epoch": 0.42,
      "grad_norm": 3.0576159954071045,
      "learning_rate": 0.00011666455133900243,
      "loss": 1.4091,
      "step": 3290
    },
    {
      "epoch": 0.42,
      "grad_norm": 22.564794540405273,
      "learning_rate": 0.00011641071201929178,
      "loss": 1.5415,
      "step": 3300
    },
    {
      "epoch": 0.42,
      "grad_norm": 3.4527130126953125,
      "learning_rate": 0.00011615687269958117,
      "loss": 1.4974,
      "step": 3310
    },
    {
      "epoch": 0.42,
      "grad_norm": 7.475599765777588,
      "learning_rate": 0.00011590303337987054,
      "loss": 1.3252,
      "step": 3320
    },
    {
      "epoch": 0.42,
      "grad_norm": 4.2747979164123535,
      "learning_rate": 0.00011564919406015993,
      "loss": 1.4975,
      "step": 3330
    },
    {
      "epoch": 0.42,
      "grad_norm": 4.640305519104004,
      "learning_rate": 0.00011539535474044928,
      "loss": 1.5271,
      "step": 3340
    },
    {
      "epoch": 0.43,
      "grad_norm": 8.948180198669434,
      "learning_rate": 0.00011514151542073868,
      "loss": 1.6516,
      "step": 3350
    },
    {
      "epoch": 0.43,
      "grad_norm": 10.231451034545898,
      "learning_rate": 0.00011488767610102807,
      "loss": 1.502,
      "step": 3360
    },
    {
      "epoch": 0.43,
      "grad_norm": 5.6130805015563965,
      "learning_rate": 0.00011463383678131743,
      "loss": 1.5691,
      "step": 3370
    },
    {
      "epoch": 0.43,
      "grad_norm": 3.253666639328003,
      "learning_rate": 0.00011437999746160681,
      "loss": 1.5259,
      "step": 3380
    },
    {
      "epoch": 0.43,
      "grad_norm": 8.89948558807373,
      "learning_rate": 0.00011412615814189618,
      "loss": 1.6401,
      "step": 3390
    },
    {
      "epoch": 0.43,
      "grad_norm": 4.759970188140869,
      "learning_rate": 0.00011387231882218557,
      "loss": 1.4659,
      "step": 3400
    },
    {
      "epoch": 0.43,
      "grad_norm": 6.952370643615723,
      "learning_rate": 0.00011361847950247493,
      "loss": 1.4183,
      "step": 3410
    },
    {
      "epoch": 0.43,
      "grad_norm": 3.1646082401275635,
      "learning_rate": 0.00011336464018276431,
      "loss": 1.5491,
      "step": 3420
    },
    {
      "epoch": 0.44,
      "grad_norm": 3.3949508666992188,
      "learning_rate": 0.0001131108008630537,
      "loss": 1.2784,
      "step": 3430
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.9452357292175293,
      "learning_rate": 0.00011285696154334307,
      "loss": 1.4064,
      "step": 3440
    },
    {
      "epoch": 0.44,
      "grad_norm": 3.07313871383667,
      "learning_rate": 0.00011260312222363245,
      "loss": 1.6188,
      "step": 3450
    },
    {
      "epoch": 0.44,
      "grad_norm": 3.7504711151123047,
      "learning_rate": 0.00011234928290392181,
      "loss": 1.3921,
      "step": 3460
    },
    {
      "epoch": 0.44,
      "grad_norm": 4.589898109436035,
      "learning_rate": 0.0001120954435842112,
      "loss": 1.4476,
      "step": 3470
    },
    {
      "epoch": 0.44,
      "grad_norm": 5.1749444007873535,
      "learning_rate": 0.00011184160426450057,
      "loss": 1.487,
      "step": 3480
    },
    {
      "epoch": 0.44,
      "grad_norm": 5.335775375366211,
      "learning_rate": 0.00011158776494478995,
      "loss": 1.303,
      "step": 3490
    },
    {
      "epoch": 0.44,
      "grad_norm": 4.827773094177246,
      "learning_rate": 0.00011133392562507934,
      "loss": 1.4925,
      "step": 3500
    },
    {
      "epoch": 0.45,
      "grad_norm": 4.58121395111084,
      "learning_rate": 0.00011108008630536871,
      "loss": 1.4668,
      "step": 3510
    },
    {
      "epoch": 0.45,
      "grad_norm": 3.44625186920166,
      "learning_rate": 0.0001108262469856581,
      "loss": 1.3944,
      "step": 3520
    },
    {
      "epoch": 0.45,
      "grad_norm": 5.276583671569824,
      "learning_rate": 0.00011057240766594745,
      "loss": 1.4402,
      "step": 3530
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.904275417327881,
      "learning_rate": 0.00011031856834623684,
      "loss": 1.3701,
      "step": 3540
    },
    {
      "epoch": 0.45,
      "grad_norm": 7.0618414878845215,
      "learning_rate": 0.00011006472902652621,
      "loss": 1.3611,
      "step": 3550
    },
    {
      "epoch": 0.45,
      "grad_norm": 5.618832111358643,
      "learning_rate": 0.0001098108897068156,
      "loss": 1.3104,
      "step": 3560
    },
    {
      "epoch": 0.45,
      "grad_norm": 5.546151638031006,
      "learning_rate": 0.00010955705038710498,
      "loss": 1.7368,
      "step": 3570
    },
    {
      "epoch": 0.45,
      "grad_norm": 5.348830223083496,
      "learning_rate": 0.00010930321106739434,
      "loss": 1.448,
      "step": 3580
    },
    {
      "epoch": 0.46,
      "grad_norm": 5.341187477111816,
      "learning_rate": 0.00010904937174768372,
      "loss": 1.3908,
      "step": 3590
    },
    {
      "epoch": 0.46,
      "grad_norm": 4.6436896324157715,
      "learning_rate": 0.00010879553242797309,
      "loss": 1.4088,
      "step": 3600
    },
    {
      "epoch": 0.46,
      "grad_norm": 5.139919757843018,
      "learning_rate": 0.00010854169310826248,
      "loss": 1.4543,
      "step": 3610
    },
    {
      "epoch": 0.46,
      "grad_norm": 4.9652099609375,
      "learning_rate": 0.00010828785378855186,
      "loss": 1.3945,
      "step": 3620
    },
    {
      "epoch": 0.46,
      "grad_norm": 8.033533096313477,
      "learning_rate": 0.00010803401446884122,
      "loss": 1.4022,
      "step": 3630
    },
    {
      "epoch": 0.46,
      "grad_norm": 4.3600969314575195,
      "learning_rate": 0.00010778017514913062,
      "loss": 1.4634,
      "step": 3640
    },
    {
      "epoch": 0.46,
      "grad_norm": 4.765228748321533,
      "learning_rate": 0.00010752633582941998,
      "loss": 1.5116,
      "step": 3650
    },
    {
      "epoch": 0.46,
      "grad_norm": 26.01957130432129,
      "learning_rate": 0.00010727249650970936,
      "loss": 1.3584,
      "step": 3660
    },
    {
      "epoch": 0.47,
      "grad_norm": 6.25186014175415,
      "learning_rate": 0.00010701865718999873,
      "loss": 1.4335,
      "step": 3670
    },
    {
      "epoch": 0.47,
      "grad_norm": 6.80491304397583,
      "learning_rate": 0.00010676481787028812,
      "loss": 1.6274,
      "step": 3680
    },
    {
      "epoch": 0.47,
      "grad_norm": 4.021554470062256,
      "learning_rate": 0.0001065109785505775,
      "loss": 1.4606,
      "step": 3690
    },
    {
      "epoch": 0.47,
      "grad_norm": 10.403332710266113,
      "learning_rate": 0.00010625713923086686,
      "loss": 1.5838,
      "step": 3700
    },
    {
      "epoch": 0.47,
      "grad_norm": 7.508678913116455,
      "learning_rate": 0.00010600329991115625,
      "loss": 1.2654,
      "step": 3710
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.879626512527466,
      "learning_rate": 0.00010574946059144562,
      "loss": 1.5151,
      "step": 3720
    },
    {
      "epoch": 0.47,
      "grad_norm": 12.97103214263916,
      "learning_rate": 0.000105495621271735,
      "loss": 1.6622,
      "step": 3730
    },
    {
      "epoch": 0.47,
      "grad_norm": 5.215634822845459,
      "learning_rate": 0.00010524178195202436,
      "loss": 1.4732,
      "step": 3740
    },
    {
      "epoch": 0.48,
      "grad_norm": 3.7422475814819336,
      "learning_rate": 0.00010498794263231375,
      "loss": 1.4823,
      "step": 3750
    },
    {
      "epoch": 0.48,
      "grad_norm": 8.680688858032227,
      "learning_rate": 0.00010473410331260313,
      "loss": 1.4644,
      "step": 3760
    },
    {
      "epoch": 0.48,
      "grad_norm": 6.674471378326416,
      "learning_rate": 0.0001044802639928925,
      "loss": 1.5762,
      "step": 3770
    },
    {
      "epoch": 0.48,
      "grad_norm": 4.908439636230469,
      "learning_rate": 0.00010422642467318189,
      "loss": 1.4404,
      "step": 3780
    },
    {
      "epoch": 0.48,
      "grad_norm": 4.879323959350586,
      "learning_rate": 0.00010397258535347125,
      "loss": 1.4988,
      "step": 3790
    },
    {
      "epoch": 0.48,
      "grad_norm": 4.0834455490112305,
      "learning_rate": 0.00010371874603376063,
      "loss": 1.3795,
      "step": 3800
    },
    {
      "epoch": 0.48,
      "grad_norm": 3.905350685119629,
      "learning_rate": 0.00010346490671405,
      "loss": 1.3569,
      "step": 3810
    },
    {
      "epoch": 0.48,
      "grad_norm": 4.434272289276123,
      "learning_rate": 0.00010321106739433939,
      "loss": 1.4346,
      "step": 3820
    },
    {
      "epoch": 0.49,
      "grad_norm": 3.369021415710449,
      "learning_rate": 0.00010295722807462877,
      "loss": 1.427,
      "step": 3830
    },
    {
      "epoch": 0.49,
      "grad_norm": 4.482950687408447,
      "learning_rate": 0.00010270338875491815,
      "loss": 1.5115,
      "step": 3840
    },
    {
      "epoch": 0.49,
      "grad_norm": 5.426779747009277,
      "learning_rate": 0.00010244954943520753,
      "loss": 1.3289,
      "step": 3850
    },
    {
      "epoch": 0.49,
      "grad_norm": 13.179872512817383,
      "learning_rate": 0.00010219571011549689,
      "loss": 1.449,
      "step": 3860
    },
    {
      "epoch": 0.49,
      "grad_norm": 4.213502883911133,
      "learning_rate": 0.00010194187079578627,
      "loss": 1.3708,
      "step": 3870
    },
    {
      "epoch": 0.49,
      "grad_norm": 8.996317863464355,
      "learning_rate": 0.00010168803147607564,
      "loss": 1.311,
      "step": 3880
    },
    {
      "epoch": 0.49,
      "grad_norm": 9.390848159790039,
      "learning_rate": 0.00010143419215636503,
      "loss": 1.5282,
      "step": 3890
    },
    {
      "epoch": 0.49,
      "grad_norm": 3.296660900115967,
      "learning_rate": 0.00010118035283665442,
      "loss": 1.4905,
      "step": 3900
    },
    {
      "epoch": 0.5,
      "grad_norm": 5.7990899085998535,
      "learning_rate": 0.00010092651351694377,
      "loss": 1.5188,
      "step": 3910
    },
    {
      "epoch": 0.5,
      "grad_norm": 5.377136707305908,
      "learning_rate": 0.00010067267419723316,
      "loss": 1.5841,
      "step": 3920
    },
    {
      "epoch": 0.5,
      "grad_norm": 4.253116607666016,
      "learning_rate": 0.00010041883487752253,
      "loss": 1.7522,
      "step": 3930
    },
    {
      "epoch": 0.5,
      "grad_norm": 4.760971546173096,
      "learning_rate": 0.00010016499555781191,
      "loss": 1.3071,
      "step": 3940
    },
    {
      "epoch": 0.5,
      "grad_norm": 4.2554144859313965,
      "learning_rate": 9.991115623810129e-05,
      "loss": 1.4601,
      "step": 3950
    },
    {
      "epoch": 0.5,
      "grad_norm": 5.888244152069092,
      "learning_rate": 9.965731691839066e-05,
      "loss": 1.3152,
      "step": 3960
    },
    {
      "epoch": 0.5,
      "grad_norm": 6.708271503448486,
      "learning_rate": 9.940347759868004e-05,
      "loss": 1.4839,
      "step": 3970
    },
    {
      "epoch": 0.51,
      "grad_norm": 4.959328651428223,
      "learning_rate": 9.914963827896941e-05,
      "loss": 1.3456,
      "step": 3980
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.69244647026062,
      "learning_rate": 9.889579895925879e-05,
      "loss": 1.4216,
      "step": 3990
    },
    {
      "epoch": 0.51,
      "grad_norm": 4.387500286102295,
      "learning_rate": 9.864195963954817e-05,
      "loss": 1.441,
      "step": 4000
    },
    {
      "epoch": 0.51,
      "grad_norm": 7.498626232147217,
      "learning_rate": 9.838812031983756e-05,
      "loss": 1.4954,
      "step": 4010
    },
    {
      "epoch": 0.51,
      "grad_norm": 4.7538743019104,
      "learning_rate": 9.813428100012693e-05,
      "loss": 1.5872,
      "step": 4020
    },
    {
      "epoch": 0.51,
      "grad_norm": 7.225889682769775,
      "learning_rate": 9.78804416804163e-05,
      "loss": 1.5146,
      "step": 4030
    },
    {
      "epoch": 0.51,
      "grad_norm": 4.596709251403809,
      "learning_rate": 9.762660236070567e-05,
      "loss": 1.4193,
      "step": 4040
    },
    {
      "epoch": 0.51,
      "grad_norm": 5.308613300323486,
      "learning_rate": 9.737276304099506e-05,
      "loss": 1.3406,
      "step": 4050
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.5017874240875244,
      "learning_rate": 9.711892372128443e-05,
      "loss": 1.5368,
      "step": 4060
    },
    {
      "epoch": 0.52,
      "grad_norm": 4.5936970710754395,
      "learning_rate": 9.686508440157381e-05,
      "loss": 1.449,
      "step": 4070
    },
    {
      "epoch": 0.52,
      "grad_norm": 3.4229328632354736,
      "learning_rate": 9.661124508186318e-05,
      "loss": 1.356,
      "step": 4080
    },
    {
      "epoch": 0.52,
      "grad_norm": 8.001469612121582,
      "learning_rate": 9.635740576215257e-05,
      "loss": 1.5504,
      "step": 4090
    },
    {
      "epoch": 0.52,
      "grad_norm": 8.435059547424316,
      "learning_rate": 9.610356644244194e-05,
      "loss": 1.4923,
      "step": 4100
    },
    {
      "epoch": 0.52,
      "grad_norm": 4.4252190589904785,
      "learning_rate": 9.584972712273131e-05,
      "loss": 1.441,
      "step": 4110
    },
    {
      "epoch": 0.52,
      "grad_norm": 6.912474632263184,
      "learning_rate": 9.559588780302068e-05,
      "loss": 1.5181,
      "step": 4120
    },
    {
      "epoch": 0.52,
      "grad_norm": 7.480644226074219,
      "learning_rate": 9.534204848331007e-05,
      "loss": 1.3035,
      "step": 4130
    },
    {
      "epoch": 0.53,
      "grad_norm": 4.814907073974609,
      "learning_rate": 9.508820916359945e-05,
      "loss": 1.3931,
      "step": 4140
    },
    {
      "epoch": 0.53,
      "grad_norm": 3.95749568939209,
      "learning_rate": 9.483436984388883e-05,
      "loss": 1.4858,
      "step": 4150
    },
    {
      "epoch": 0.53,
      "grad_norm": 3.2968997955322266,
      "learning_rate": 9.45805305241782e-05,
      "loss": 1.1854,
      "step": 4160
    },
    {
      "epoch": 0.53,
      "grad_norm": 4.224449157714844,
      "learning_rate": 9.432669120446758e-05,
      "loss": 1.4856,
      "step": 4170
    },
    {
      "epoch": 0.53,
      "grad_norm": 3.9060184955596924,
      "learning_rate": 9.407285188475695e-05,
      "loss": 1.5625,
      "step": 4180
    },
    {
      "epoch": 0.53,
      "grad_norm": 5.574713706970215,
      "learning_rate": 9.381901256504632e-05,
      "loss": 1.4375,
      "step": 4190
    },
    {
      "epoch": 0.53,
      "grad_norm": 6.0658040046691895,
      "learning_rate": 9.35651732453357e-05,
      "loss": 1.4088,
      "step": 4200
    },
    {
      "epoch": 0.53,
      "grad_norm": 4.851366996765137,
      "learning_rate": 9.33113339256251e-05,
      "loss": 1.3577,
      "step": 4210
    },
    {
      "epoch": 0.54,
      "grad_norm": 4.407389163970947,
      "learning_rate": 9.305749460591447e-05,
      "loss": 1.3761,
      "step": 4220
    },
    {
      "epoch": 0.54,
      "grad_norm": 3.0154011249542236,
      "learning_rate": 9.280365528620384e-05,
      "loss": 1.3324,
      "step": 4230
    },
    {
      "epoch": 0.54,
      "grad_norm": 3.01029372215271,
      "learning_rate": 9.254981596649321e-05,
      "loss": 1.5156,
      "step": 4240
    },
    {
      "epoch": 0.54,
      "grad_norm": 3.4258463382720947,
      "learning_rate": 9.22959766467826e-05,
      "loss": 1.5092,
      "step": 4250
    },
    {
      "epoch": 0.54,
      "grad_norm": 10.476564407348633,
      "learning_rate": 9.204213732707197e-05,
      "loss": 1.1886,
      "step": 4260
    },
    {
      "epoch": 0.54,
      "grad_norm": 5.821480751037598,
      "learning_rate": 9.178829800736134e-05,
      "loss": 1.6297,
      "step": 4270
    },
    {
      "epoch": 0.54,
      "grad_norm": 4.895218372344971,
      "learning_rate": 9.153445868765072e-05,
      "loss": 1.4472,
      "step": 4280
    },
    {
      "epoch": 0.54,
      "grad_norm": 4.214102268218994,
      "learning_rate": 9.128061936794011e-05,
      "loss": 1.3905,
      "step": 4290
    },
    {
      "epoch": 0.55,
      "grad_norm": 4.729639053344727,
      "learning_rate": 9.102678004822948e-05,
      "loss": 1.2915,
      "step": 4300
    },
    {
      "epoch": 0.55,
      "grad_norm": 6.503230094909668,
      "learning_rate": 9.077294072851885e-05,
      "loss": 1.4292,
      "step": 4310
    },
    {
      "epoch": 0.55,
      "grad_norm": 6.148368835449219,
      "learning_rate": 9.051910140880822e-05,
      "loss": 1.3435,
      "step": 4320
    },
    {
      "epoch": 0.55,
      "grad_norm": 3.530411958694458,
      "learning_rate": 9.026526208909761e-05,
      "loss": 1.136,
      "step": 4330
    },
    {
      "epoch": 0.55,
      "grad_norm": 3.3677561283111572,
      "learning_rate": 9.001142276938698e-05,
      "loss": 1.5316,
      "step": 4340
    },
    {
      "epoch": 0.55,
      "grad_norm": 7.070441246032715,
      "learning_rate": 8.975758344967636e-05,
      "loss": 1.5483,
      "step": 4350
    },
    {
      "epoch": 0.55,
      "grad_norm": 7.054075241088867,
      "learning_rate": 8.950374412996574e-05,
      "loss": 1.6255,
      "step": 4360
    },
    {
      "epoch": 0.55,
      "grad_norm": 4.765869140625,
      "learning_rate": 8.924990481025512e-05,
      "loss": 1.3229,
      "step": 4370
    },
    {
      "epoch": 0.56,
      "grad_norm": 5.33497428894043,
      "learning_rate": 8.899606549054449e-05,
      "loss": 1.5481,
      "step": 4380
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.660428762435913,
      "learning_rate": 8.874222617083386e-05,
      "loss": 1.4056,
      "step": 4390
    },
    {
      "epoch": 0.56,
      "grad_norm": 3.3315839767456055,
      "learning_rate": 8.848838685112324e-05,
      "loss": 1.3567,
      "step": 4400
    },
    {
      "epoch": 0.56,
      "grad_norm": 6.890965938568115,
      "learning_rate": 8.823454753141262e-05,
      "loss": 1.5214,
      "step": 4410
    },
    {
      "epoch": 0.56,
      "grad_norm": 4.836705207824707,
      "learning_rate": 8.7980708211702e-05,
      "loss": 1.4183,
      "step": 4420
    },
    {
      "epoch": 0.56,
      "grad_norm": 5.25673770904541,
      "learning_rate": 8.772686889199138e-05,
      "loss": 1.5025,
      "step": 4430
    },
    {
      "epoch": 0.56,
      "grad_norm": 3.9640564918518066,
      "learning_rate": 8.747302957228075e-05,
      "loss": 1.3821,
      "step": 4440
    },
    {
      "epoch": 0.56,
      "grad_norm": 3.2193267345428467,
      "learning_rate": 8.721919025257012e-05,
      "loss": 1.5492,
      "step": 4450
    },
    {
      "epoch": 0.57,
      "grad_norm": 9.101642608642578,
      "learning_rate": 8.69653509328595e-05,
      "loss": 1.7339,
      "step": 4460
    },
    {
      "epoch": 0.57,
      "grad_norm": 5.326535701751709,
      "learning_rate": 8.671151161314888e-05,
      "loss": 1.5151,
      "step": 4470
    },
    {
      "epoch": 0.57,
      "grad_norm": 4.039443016052246,
      "learning_rate": 8.645767229343826e-05,
      "loss": 1.3442,
      "step": 4480
    },
    {
      "epoch": 0.57,
      "grad_norm": 7.351093292236328,
      "learning_rate": 8.620383297372763e-05,
      "loss": 1.5902,
      "step": 4490
    },
    {
      "epoch": 0.57,
      "grad_norm": 5.267037391662598,
      "learning_rate": 8.594999365401702e-05,
      "loss": 1.4483,
      "step": 4500
    },
    {
      "epoch": 0.57,
      "grad_norm": 4.324281215667725,
      "learning_rate": 8.569615433430639e-05,
      "loss": 1.4515,
      "step": 4510
    },
    {
      "epoch": 0.57,
      "grad_norm": 8.07254695892334,
      "learning_rate": 8.544231501459576e-05,
      "loss": 1.6396,
      "step": 4520
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.736769676208496,
      "learning_rate": 8.518847569488513e-05,
      "loss": 1.551,
      "step": 4530
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.6389269828796387,
      "learning_rate": 8.493463637517452e-05,
      "loss": 1.427,
      "step": 4540
    },
    {
      "epoch": 0.58,
      "grad_norm": 4.601314544677734,
      "learning_rate": 8.46807970554639e-05,
      "loss": 1.4644,
      "step": 4550
    },
    {
      "epoch": 0.58,
      "grad_norm": 3.502492904663086,
      "learning_rate": 8.442695773575327e-05,
      "loss": 1.489,
      "step": 4560
    },
    {
      "epoch": 0.58,
      "grad_norm": 4.4823737144470215,
      "learning_rate": 8.417311841604265e-05,
      "loss": 1.5216,
      "step": 4570
    },
    {
      "epoch": 0.58,
      "grad_norm": 9.208209991455078,
      "learning_rate": 8.391927909633203e-05,
      "loss": 1.5139,
      "step": 4580
    },
    {
      "epoch": 0.58,
      "grad_norm": 9.83117961883545,
      "learning_rate": 8.36654397766214e-05,
      "loss": 1.5243,
      "step": 4590
    },
    {
      "epoch": 0.58,
      "grad_norm": 5.654240608215332,
      "learning_rate": 8.341160045691077e-05,
      "loss": 1.5948,
      "step": 4600
    },
    {
      "epoch": 0.59,
      "grad_norm": 5.105128288269043,
      "learning_rate": 8.315776113720015e-05,
      "loss": 1.3728,
      "step": 4610
    },
    {
      "epoch": 0.59,
      "grad_norm": 3.297628402709961,
      "learning_rate": 8.290392181748954e-05,
      "loss": 1.464,
      "step": 4620
    },
    {
      "epoch": 0.59,
      "grad_norm": 6.719997406005859,
      "learning_rate": 8.265008249777892e-05,
      "loss": 1.3071,
      "step": 4630
    },
    {
      "epoch": 0.59,
      "grad_norm": 3.180598735809326,
      "learning_rate": 8.239624317806829e-05,
      "loss": 1.1998,
      "step": 4640
    },
    {
      "epoch": 0.59,
      "grad_norm": 4.772474765777588,
      "learning_rate": 8.214240385835766e-05,
      "loss": 1.44,
      "step": 4650
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.6236679553985596,
      "learning_rate": 8.188856453864704e-05,
      "loss": 1.4634,
      "step": 4660
    },
    {
      "epoch": 0.59,
      "grad_norm": 6.366898059844971,
      "learning_rate": 8.163472521893642e-05,
      "loss": 1.4251,
      "step": 4670
    },
    {
      "epoch": 0.59,
      "grad_norm": 4.368298530578613,
      "learning_rate": 8.138088589922579e-05,
      "loss": 1.4537,
      "step": 4680
    },
    {
      "epoch": 0.6,
      "grad_norm": 4.059544563293457,
      "learning_rate": 8.112704657951517e-05,
      "loss": 1.5841,
      "step": 4690
    },
    {
      "epoch": 0.6,
      "grad_norm": 4.95836877822876,
      "learning_rate": 8.087320725980456e-05,
      "loss": 1.5292,
      "step": 4700
    },
    {
      "epoch": 0.6,
      "grad_norm": 8.796601295471191,
      "learning_rate": 8.061936794009393e-05,
      "loss": 1.5807,
      "step": 4710
    },
    {
      "epoch": 0.6,
      "grad_norm": 4.097345352172852,
      "learning_rate": 8.03655286203833e-05,
      "loss": 1.3082,
      "step": 4720
    },
    {
      "epoch": 0.6,
      "grad_norm": 15.605876922607422,
      "learning_rate": 8.011168930067267e-05,
      "loss": 1.2493,
      "step": 4730
    },
    {
      "epoch": 0.6,
      "grad_norm": 6.575037956237793,
      "learning_rate": 7.985784998096206e-05,
      "loss": 1.2814,
      "step": 4740
    },
    {
      "epoch": 0.6,
      "grad_norm": 4.231520652770996,
      "learning_rate": 7.960401066125143e-05,
      "loss": 1.2926,
      "step": 4750
    },
    {
      "epoch": 0.6,
      "grad_norm": 3.914984703063965,
      "learning_rate": 7.935017134154081e-05,
      "loss": 1.3575,
      "step": 4760
    },
    {
      "epoch": 0.61,
      "grad_norm": 8.397192001342773,
      "learning_rate": 7.909633202183018e-05,
      "loss": 1.4945,
      "step": 4770
    },
    {
      "epoch": 0.61,
      "grad_norm": 7.447240352630615,
      "learning_rate": 7.884249270211957e-05,
      "loss": 1.3094,
      "step": 4780
    },
    {
      "epoch": 0.61,
      "grad_norm": 6.533170223236084,
      "learning_rate": 7.858865338240894e-05,
      "loss": 1.5625,
      "step": 4790
    },
    {
      "epoch": 0.61,
      "grad_norm": 3.640164375305176,
      "learning_rate": 7.833481406269831e-05,
      "loss": 1.5239,
      "step": 4800
    },
    {
      "epoch": 0.61,
      "grad_norm": 3.061248779296875,
      "learning_rate": 7.808097474298768e-05,
      "loss": 1.655,
      "step": 4810
    },
    {
      "epoch": 0.61,
      "grad_norm": 6.345325946807861,
      "learning_rate": 7.782713542327707e-05,
      "loss": 1.2693,
      "step": 4820
    },
    {
      "epoch": 0.61,
      "grad_norm": 4.143004417419434,
      "learning_rate": 7.757329610356645e-05,
      "loss": 1.5835,
      "step": 4830
    },
    {
      "epoch": 0.61,
      "grad_norm": 4.644939422607422,
      "learning_rate": 7.731945678385583e-05,
      "loss": 1.39,
      "step": 4840
    },
    {
      "epoch": 0.62,
      "grad_norm": 3.241922378540039,
      "learning_rate": 7.70656174641452e-05,
      "loss": 1.3353,
      "step": 4850
    },
    {
      "epoch": 0.62,
      "grad_norm": 4.355912208557129,
      "learning_rate": 7.681177814443458e-05,
      "loss": 1.1671,
      "step": 4860
    },
    {
      "epoch": 0.62,
      "grad_norm": 4.103896617889404,
      "learning_rate": 7.655793882472395e-05,
      "loss": 1.6326,
      "step": 4870
    },
    {
      "epoch": 0.62,
      "grad_norm": 3.840471029281616,
      "learning_rate": 7.630409950501333e-05,
      "loss": 1.5097,
      "step": 4880
    },
    {
      "epoch": 0.62,
      "grad_norm": 3.5507798194885254,
      "learning_rate": 7.60502601853027e-05,
      "loss": 1.4306,
      "step": 4890
    },
    {
      "epoch": 0.62,
      "grad_norm": 5.515477657318115,
      "learning_rate": 7.579642086559208e-05,
      "loss": 1.3138,
      "step": 4900
    },
    {
      "epoch": 0.62,
      "grad_norm": 4.944309711456299,
      "learning_rate": 7.554258154588147e-05,
      "loss": 1.536,
      "step": 4910
    },
    {
      "epoch": 0.62,
      "grad_norm": 4.8006815910339355,
      "learning_rate": 7.528874222617084e-05,
      "loss": 1.3659,
      "step": 4920
    },
    {
      "epoch": 0.63,
      "grad_norm": 5.4206461906433105,
      "learning_rate": 7.503490290646021e-05,
      "loss": 1.5448,
      "step": 4930
    },
    {
      "epoch": 0.63,
      "grad_norm": 3.2793920040130615,
      "learning_rate": 7.47810635867496e-05,
      "loss": 1.4196,
      "step": 4940
    },
    {
      "epoch": 0.63,
      "grad_norm": 5.160758972167969,
      "learning_rate": 7.452722426703897e-05,
      "loss": 1.4268,
      "step": 4950
    },
    {
      "epoch": 0.63,
      "grad_norm": 6.132502555847168,
      "learning_rate": 7.427338494732834e-05,
      "loss": 1.36,
      "step": 4960
    },
    {
      "epoch": 0.63,
      "grad_norm": 3.9804413318634033,
      "learning_rate": 7.401954562761772e-05,
      "loss": 1.4618,
      "step": 4970
    },
    {
      "epoch": 0.63,
      "grad_norm": 3.964646100997925,
      "learning_rate": 7.37657063079071e-05,
      "loss": 1.4482,
      "step": 4980
    },
    {
      "epoch": 0.63,
      "grad_norm": 3.847047805786133,
      "learning_rate": 7.351186698819648e-05,
      "loss": 1.2763,
      "step": 4990
    },
    {
      "epoch": 0.63,
      "grad_norm": 4.500941276550293,
      "learning_rate": 7.325802766848585e-05,
      "loss": 1.354,
      "step": 5000
    },
    {
      "epoch": 0.64,
      "grad_norm": 5.0733208656311035,
      "learning_rate": 7.300418834877522e-05,
      "loss": 1.7707,
      "step": 5010
    },
    {
      "epoch": 0.64,
      "grad_norm": 4.024664878845215,
      "learning_rate": 7.27503490290646e-05,
      "loss": 1.3917,
      "step": 5020
    },
    {
      "epoch": 0.64,
      "grad_norm": 5.336170673370361,
      "learning_rate": 7.249650970935398e-05,
      "loss": 1.501,
      "step": 5030
    },
    {
      "epoch": 0.64,
      "grad_norm": 3.8697478771209717,
      "learning_rate": 7.224267038964337e-05,
      "loss": 1.4786,
      "step": 5040
    },
    {
      "epoch": 0.64,
      "grad_norm": 3.5920469760894775,
      "learning_rate": 7.198883106993274e-05,
      "loss": 1.3516,
      "step": 5050
    },
    {
      "epoch": 0.64,
      "grad_norm": 4.948923110961914,
      "learning_rate": 7.173499175022211e-05,
      "loss": 1.5268,
      "step": 5060
    },
    {
      "epoch": 0.64,
      "grad_norm": 5.148724555969238,
      "learning_rate": 7.14811524305115e-05,
      "loss": 1.5148,
      "step": 5070
    },
    {
      "epoch": 0.64,
      "grad_norm": 5.712954044342041,
      "learning_rate": 7.122731311080086e-05,
      "loss": 1.5824,
      "step": 5080
    },
    {
      "epoch": 0.65,
      "grad_norm": 3.353522539138794,
      "learning_rate": 7.097347379109024e-05,
      "loss": 1.4945,
      "step": 5090
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.7437822818756104,
      "learning_rate": 7.071963447137962e-05,
      "loss": 1.3235,
      "step": 5100
    },
    {
      "epoch": 0.65,
      "grad_norm": 3.6879332065582275,
      "learning_rate": 7.0465795151669e-05,
      "loss": 1.2979,
      "step": 5110
    },
    {
      "epoch": 0.65,
      "grad_norm": 4.472382545471191,
      "learning_rate": 7.021195583195838e-05,
      "loss": 1.5998,
      "step": 5120
    },
    {
      "epoch": 0.65,
      "grad_norm": 6.1999616622924805,
      "learning_rate": 6.995811651224775e-05,
      "loss": 1.3387,
      "step": 5130
    },
    {
      "epoch": 0.65,
      "grad_norm": 4.411257743835449,
      "learning_rate": 6.970427719253712e-05,
      "loss": 1.4338,
      "step": 5140
    },
    {
      "epoch": 0.65,
      "grad_norm": 4.742552757263184,
      "learning_rate": 6.94504378728265e-05,
      "loss": 1.5874,
      "step": 5150
    },
    {
      "epoch": 0.65,
      "grad_norm": 3.176253318786621,
      "learning_rate": 6.919659855311588e-05,
      "loss": 1.4118,
      "step": 5160
    },
    {
      "epoch": 0.66,
      "grad_norm": 3.6899313926696777,
      "learning_rate": 6.894275923340526e-05,
      "loss": 1.5701,
      "step": 5170
    },
    {
      "epoch": 0.66,
      "grad_norm": 4.152185440063477,
      "learning_rate": 6.868891991369463e-05,
      "loss": 1.4143,
      "step": 5180
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.8579165935516357,
      "learning_rate": 6.843508059398402e-05,
      "loss": 1.3877,
      "step": 5190
    },
    {
      "epoch": 0.66,
      "grad_norm": 3.1757075786590576,
      "learning_rate": 6.818124127427339e-05,
      "loss": 1.2726,
      "step": 5200
    },
    {
      "epoch": 0.66,
      "grad_norm": 3.4718799591064453,
      "learning_rate": 6.792740195456276e-05,
      "loss": 1.3802,
      "step": 5210
    },
    {
      "epoch": 0.66,
      "grad_norm": 3.155165433883667,
      "learning_rate": 6.767356263485213e-05,
      "loss": 1.3931,
      "step": 5220
    },
    {
      "epoch": 0.66,
      "grad_norm": 3.354926109313965,
      "learning_rate": 6.741972331514152e-05,
      "loss": 1.4882,
      "step": 5230
    },
    {
      "epoch": 0.67,
      "grad_norm": 3.80718731880188,
      "learning_rate": 6.71658839954309e-05,
      "loss": 1.283,
      "step": 5240
    },
    {
      "epoch": 0.67,
      "grad_norm": 3.1644816398620605,
      "learning_rate": 6.691204467572028e-05,
      "loss": 1.4014,
      "step": 5250
    },
    {
      "epoch": 0.67,
      "grad_norm": 4.281290531158447,
      "learning_rate": 6.665820535600965e-05,
      "loss": 1.4314,
      "step": 5260
    },
    {
      "epoch": 0.67,
      "grad_norm": 3.299412250518799,
      "learning_rate": 6.640436603629903e-05,
      "loss": 1.4403,
      "step": 5270
    },
    {
      "epoch": 0.67,
      "grad_norm": 3.430976152420044,
      "learning_rate": 6.61505267165884e-05,
      "loss": 1.4262,
      "step": 5280
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.989061117172241,
      "learning_rate": 6.589668739687778e-05,
      "loss": 1.3982,
      "step": 5290
    },
    {
      "epoch": 0.67,
      "grad_norm": 4.242211818695068,
      "learning_rate": 6.564284807716715e-05,
      "loss": 1.5178,
      "step": 5300
    },
    {
      "epoch": 0.67,
      "grad_norm": 3.888242721557617,
      "learning_rate": 6.538900875745653e-05,
      "loss": 1.4134,
      "step": 5310
    },
    {
      "epoch": 0.68,
      "grad_norm": 3.277520179748535,
      "learning_rate": 6.513516943774592e-05,
      "loss": 1.3992,
      "step": 5320
    },
    {
      "epoch": 0.68,
      "grad_norm": 10.241342544555664,
      "learning_rate": 6.488133011803529e-05,
      "loss": 1.513,
      "step": 5330
    },
    {
      "epoch": 0.68,
      "grad_norm": 3.4279167652130127,
      "learning_rate": 6.462749079832466e-05,
      "loss": 1.5499,
      "step": 5340
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.413529872894287,
      "learning_rate": 6.437365147861405e-05,
      "loss": 1.2511,
      "step": 5350
    },
    {
      "epoch": 0.68,
      "grad_norm": 5.1270527839660645,
      "learning_rate": 6.411981215890342e-05,
      "loss": 1.4566,
      "step": 5360
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.3108649253845215,
      "learning_rate": 6.386597283919279e-05,
      "loss": 1.3823,
      "step": 5370
    },
    {
      "epoch": 0.68,
      "grad_norm": 4.448211669921875,
      "learning_rate": 6.361213351948217e-05,
      "loss": 1.456,
      "step": 5380
    },
    {
      "epoch": 0.68,
      "grad_norm": 4.660693645477295,
      "learning_rate": 6.335829419977154e-05,
      "loss": 1.4187,
      "step": 5390
    },
    {
      "epoch": 0.69,
      "grad_norm": 7.539705276489258,
      "learning_rate": 6.310445488006093e-05,
      "loss": 1.3733,
      "step": 5400
    },
    {
      "epoch": 0.69,
      "grad_norm": 3.222687244415283,
      "learning_rate": 6.28506155603503e-05,
      "loss": 1.4509,
      "step": 5410
    },
    {
      "epoch": 0.69,
      "grad_norm": 6.3772735595703125,
      "learning_rate": 6.259677624063967e-05,
      "loss": 1.5683,
      "step": 5420
    },
    {
      "epoch": 0.69,
      "grad_norm": 5.016027927398682,
      "learning_rate": 6.234293692092906e-05,
      "loss": 1.5536,
      "step": 5430
    },
    {
      "epoch": 0.69,
      "grad_norm": 8.178925514221191,
      "learning_rate": 6.208909760121843e-05,
      "loss": 1.4222,
      "step": 5440
    },
    {
      "epoch": 0.69,
      "grad_norm": 3.2475616931915283,
      "learning_rate": 6.183525828150781e-05,
      "loss": 1.566,
      "step": 5450
    },
    {
      "epoch": 0.69,
      "grad_norm": 3.3581719398498535,
      "learning_rate": 6.158141896179719e-05,
      "loss": 1.5241,
      "step": 5460
    },
    {
      "epoch": 0.69,
      "grad_norm": 3.8377938270568848,
      "learning_rate": 6.132757964208656e-05,
      "loss": 1.5206,
      "step": 5470
    },
    {
      "epoch": 0.7,
      "grad_norm": 3.3370201587677,
      "learning_rate": 6.107374032237594e-05,
      "loss": 1.282,
      "step": 5480
    },
    {
      "epoch": 0.7,
      "grad_norm": 6.1774444580078125,
      "learning_rate": 6.0819901002665314e-05,
      "loss": 1.4145,
      "step": 5490
    },
    {
      "epoch": 0.7,
      "grad_norm": 6.429939270019531,
      "learning_rate": 6.0566061682954686e-05,
      "loss": 1.376,
      "step": 5500
    },
    {
      "epoch": 0.7,
      "grad_norm": 3.393505096435547,
      "learning_rate": 6.0312222363244064e-05,
      "loss": 1.5664,
      "step": 5510
    },
    {
      "epoch": 0.7,
      "grad_norm": 6.031446933746338,
      "learning_rate": 6.005838304353345e-05,
      "loss": 1.4033,
      "step": 5520
    },
    {
      "epoch": 0.7,
      "grad_norm": 3.337427854537964,
      "learning_rate": 5.980454372382283e-05,
      "loss": 1.3212,
      "step": 5530
    },
    {
      "epoch": 0.7,
      "grad_norm": 4.156692981719971,
      "learning_rate": 5.95507044041122e-05,
      "loss": 1.4477,
      "step": 5540
    },
    {
      "epoch": 0.7,
      "grad_norm": 3.811351776123047,
      "learning_rate": 5.929686508440158e-05,
      "loss": 1.2709,
      "step": 5550
    },
    {
      "epoch": 0.71,
      "grad_norm": 3.067619800567627,
      "learning_rate": 5.904302576469095e-05,
      "loss": 1.4914,
      "step": 5560
    },
    {
      "epoch": 0.71,
      "grad_norm": 4.118954181671143,
      "learning_rate": 5.878918644498033e-05,
      "loss": 1.3454,
      "step": 5570
    },
    {
      "epoch": 0.71,
      "grad_norm": 3.779064416885376,
      "learning_rate": 5.85353471252697e-05,
      "loss": 1.3018,
      "step": 5580
    },
    {
      "epoch": 0.71,
      "grad_norm": 3.504819631576538,
      "learning_rate": 5.828150780555909e-05,
      "loss": 1.3453,
      "step": 5590
    },
    {
      "epoch": 0.71,
      "grad_norm": 6.01574182510376,
      "learning_rate": 5.802766848584846e-05,
      "loss": 1.5315,
      "step": 5600
    },
    {
      "epoch": 0.71,
      "grad_norm": 5.731825828552246,
      "learning_rate": 5.777382916613784e-05,
      "loss": 1.4414,
      "step": 5610
    },
    {
      "epoch": 0.71,
      "grad_norm": 3.9339139461517334,
      "learning_rate": 5.751998984642721e-05,
      "loss": 1.6364,
      "step": 5620
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.6754653453826904,
      "learning_rate": 5.726615052671659e-05,
      "loss": 1.3482,
      "step": 5630
    },
    {
      "epoch": 0.72,
      "grad_norm": 3.7664310932159424,
      "learning_rate": 5.701231120700596e-05,
      "loss": 1.3847,
      "step": 5640
    },
    {
      "epoch": 0.72,
      "grad_norm": 5.40439510345459,
      "learning_rate": 5.6758471887295353e-05,
      "loss": 1.3176,
      "step": 5650
    },
    {
      "epoch": 0.72,
      "grad_norm": 6.088896751403809,
      "learning_rate": 5.6504632567584725e-05,
      "loss": 1.413,
      "step": 5660
    },
    {
      "epoch": 0.72,
      "grad_norm": 3.106816053390503,
      "learning_rate": 5.62507932478741e-05,
      "loss": 1.4928,
      "step": 5670
    },
    {
      "epoch": 0.72,
      "grad_norm": 5.382909774780273,
      "learning_rate": 5.5996953928163475e-05,
      "loss": 1.5245,
      "step": 5680
    },
    {
      "epoch": 0.72,
      "grad_norm": 4.180933952331543,
      "learning_rate": 5.574311460845285e-05,
      "loss": 1.4236,
      "step": 5690
    },
    {
      "epoch": 0.72,
      "grad_norm": 4.191691875457764,
      "learning_rate": 5.5489275288742225e-05,
      "loss": 1.4104,
      "step": 5700
    },
    {
      "epoch": 0.72,
      "grad_norm": 3.3269801139831543,
      "learning_rate": 5.52354359690316e-05,
      "loss": 1.2355,
      "step": 5710
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.7112197875976562,
      "learning_rate": 5.498159664932099e-05,
      "loss": 1.3317,
      "step": 5720
    },
    {
      "epoch": 0.73,
      "grad_norm": 4.898848056793213,
      "learning_rate": 5.4727757329610366e-05,
      "loss": 1.4803,
      "step": 5730
    },
    {
      "epoch": 0.73,
      "grad_norm": 6.735752105712891,
      "learning_rate": 5.447391800989974e-05,
      "loss": 1.6261,
      "step": 5740
    },
    {
      "epoch": 0.73,
      "grad_norm": 5.549077987670898,
      "learning_rate": 5.4220078690189116e-05,
      "loss": 1.494,
      "step": 5750
    },
    {
      "epoch": 0.73,
      "grad_norm": 3.751390218734741,
      "learning_rate": 5.396623937047849e-05,
      "loss": 1.3401,
      "step": 5760
    },
    {
      "epoch": 0.73,
      "grad_norm": 5.769964218139648,
      "learning_rate": 5.3712400050767866e-05,
      "loss": 1.5919,
      "step": 5770
    },
    {
      "epoch": 0.73,
      "grad_norm": 3.0451529026031494,
      "learning_rate": 5.345856073105724e-05,
      "loss": 1.5005,
      "step": 5780
    },
    {
      "epoch": 0.73,
      "grad_norm": 6.941451549530029,
      "learning_rate": 5.320472141134662e-05,
      "loss": 1.4273,
      "step": 5790
    },
    {
      "epoch": 0.74,
      "grad_norm": 3.537308931350708,
      "learning_rate": 5.2950882091636e-05,
      "loss": 1.3521,
      "step": 5800
    },
    {
      "epoch": 0.74,
      "grad_norm": 4.005722522735596,
      "learning_rate": 5.269704277192537e-05,
      "loss": 1.5383,
      "step": 5810
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.4536757469177246,
      "learning_rate": 5.244320345221475e-05,
      "loss": 1.2749,
      "step": 5820
    },
    {
      "epoch": 0.74,
      "grad_norm": 3.1454529762268066,
      "learning_rate": 5.218936413250413e-05,
      "loss": 1.3919,
      "step": 5830
    },
    {
      "epoch": 0.74,
      "grad_norm": 5.3287672996521,
      "learning_rate": 5.19355248127935e-05,
      "loss": 1.5463,
      "step": 5840
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.8944804668426514,
      "learning_rate": 5.168168549308288e-05,
      "loss": 1.202,
      "step": 5850
    },
    {
      "epoch": 0.74,
      "grad_norm": 5.853376388549805,
      "learning_rate": 5.1427846173372264e-05,
      "loss": 1.5843,
      "step": 5860
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.6840198040008545,
      "learning_rate": 5.1174006853661635e-05,
      "loss": 1.5766,
      "step": 5870
    },
    {
      "epoch": 0.75,
      "grad_norm": 5.243074893951416,
      "learning_rate": 5.0920167533951014e-05,
      "loss": 1.5103,
      "step": 5880
    },
    {
      "epoch": 0.75,
      "grad_norm": 4.504575729370117,
      "learning_rate": 5.0666328214240385e-05,
      "loss": 1.7399,
      "step": 5890
    },
    {
      "epoch": 0.75,
      "grad_norm": 4.0400614738464355,
      "learning_rate": 5.0412488894529764e-05,
      "loss": 1.4215,
      "step": 5900
    },
    {
      "epoch": 0.75,
      "grad_norm": 5.049299716949463,
      "learning_rate": 5.015864957481914e-05,
      "loss": 1.3222,
      "step": 5910
    },
    {
      "epoch": 0.75,
      "grad_norm": 5.02110481262207,
      "learning_rate": 4.990481025510852e-05,
      "loss": 1.3259,
      "step": 5920
    },
    {
      "epoch": 0.75,
      "grad_norm": 10.374341011047363,
      "learning_rate": 4.965097093539789e-05,
      "loss": 1.3415,
      "step": 5930
    },
    {
      "epoch": 0.75,
      "grad_norm": 16.343854904174805,
      "learning_rate": 4.939713161568727e-05,
      "loss": 1.3746,
      "step": 5940
    },
    {
      "epoch": 0.76,
      "grad_norm": 3.2567026615142822,
      "learning_rate": 4.914329229597665e-05,
      "loss": 1.6395,
      "step": 5950
    },
    {
      "epoch": 0.76,
      "grad_norm": 4.854289531707764,
      "learning_rate": 4.8889452976266027e-05,
      "loss": 1.433,
      "step": 5960
    },
    {
      "epoch": 0.76,
      "grad_norm": 4.380673885345459,
      "learning_rate": 4.86356136565554e-05,
      "loss": 1.3019,
      "step": 5970
    },
    {
      "epoch": 0.76,
      "grad_norm": 3.3379714488983154,
      "learning_rate": 4.838177433684478e-05,
      "loss": 1.4188,
      "step": 5980
    },
    {
      "epoch": 0.76,
      "grad_norm": 4.432158470153809,
      "learning_rate": 4.8127935017134155e-05,
      "loss": 1.4316,
      "step": 5990
    },
    {
      "epoch": 0.76,
      "grad_norm": 7.806492328643799,
      "learning_rate": 4.787409569742353e-05,
      "loss": 1.4454,
      "step": 6000
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.752359390258789,
      "learning_rate": 4.7620256377712904e-05,
      "loss": 1.3878,
      "step": 6010
    },
    {
      "epoch": 0.76,
      "grad_norm": 3.4831576347351074,
      "learning_rate": 4.736641705800229e-05,
      "loss": 1.2152,
      "step": 6020
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.531665802001953,
      "learning_rate": 4.711257773829166e-05,
      "loss": 1.3239,
      "step": 6030
    },
    {
      "epoch": 0.77,
      "grad_norm": 6.2874040603637695,
      "learning_rate": 4.685873841858104e-05,
      "loss": 1.3429,
      "step": 6040
    },
    {
      "epoch": 0.77,
      "grad_norm": 3.840137243270874,
      "learning_rate": 4.660489909887042e-05,
      "loss": 1.333,
      "step": 6050
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.618727684020996,
      "learning_rate": 4.6351059779159796e-05,
      "loss": 1.3284,
      "step": 6060
    },
    {
      "epoch": 0.77,
      "grad_norm": 3.3073606491088867,
      "learning_rate": 4.609722045944917e-05,
      "loss": 1.5526,
      "step": 6070
    },
    {
      "epoch": 0.77,
      "grad_norm": 4.204127311706543,
      "learning_rate": 4.584338113973855e-05,
      "loss": 1.3523,
      "step": 6080
    },
    {
      "epoch": 0.77,
      "grad_norm": 5.2699151039123535,
      "learning_rate": 4.5589541820027924e-05,
      "loss": 1.4999,
      "step": 6090
    },
    {
      "epoch": 0.77,
      "grad_norm": 3.544842004776001,
      "learning_rate": 4.53357025003173e-05,
      "loss": 1.4187,
      "step": 6100
    },
    {
      "epoch": 0.78,
      "grad_norm": 3.6791799068450928,
      "learning_rate": 4.5081863180606674e-05,
      "loss": 1.5947,
      "step": 6110
    },
    {
      "epoch": 0.78,
      "grad_norm": 4.5190887451171875,
      "learning_rate": 4.482802386089606e-05,
      "loss": 1.5038,
      "step": 6120
    },
    {
      "epoch": 0.78,
      "grad_norm": 3.22074031829834,
      "learning_rate": 4.457418454118543e-05,
      "loss": 1.3688,
      "step": 6130
    },
    {
      "epoch": 0.78,
      "grad_norm": 3.94370174407959,
      "learning_rate": 4.432034522147481e-05,
      "loss": 1.4972,
      "step": 6140
    },
    {
      "epoch": 0.78,
      "grad_norm": 4.834630012512207,
      "learning_rate": 4.406650590176419e-05,
      "loss": 1.3846,
      "step": 6150
    },
    {
      "epoch": 0.78,
      "grad_norm": 3.9594907760620117,
      "learning_rate": 4.3812666582053565e-05,
      "loss": 1.3615,
      "step": 6160
    },
    {
      "epoch": 0.78,
      "grad_norm": 4.223938465118408,
      "learning_rate": 4.355882726234294e-05,
      "loss": 1.6801,
      "step": 6170
    },
    {
      "epoch": 0.78,
      "grad_norm": 3.82785701751709,
      "learning_rate": 4.3304987942632315e-05,
      "loss": 1.4464,
      "step": 6180
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.2846176624298096,
      "learning_rate": 4.3051148622921694e-05,
      "loss": 1.4842,
      "step": 6190
    },
    {
      "epoch": 0.79,
      "grad_norm": 5.191291332244873,
      "learning_rate": 4.279730930321107e-05,
      "loss": 1.6131,
      "step": 6200
    },
    {
      "epoch": 0.79,
      "grad_norm": 4.570377826690674,
      "learning_rate": 4.2543469983500443e-05,
      "loss": 1.3882,
      "step": 6210
    },
    {
      "epoch": 0.79,
      "grad_norm": 3.2673840522766113,
      "learning_rate": 4.228963066378983e-05,
      "loss": 1.3657,
      "step": 6220
    },
    {
      "epoch": 0.79,
      "grad_norm": 4.52858829498291,
      "learning_rate": 4.20357913440792e-05,
      "loss": 1.5349,
      "step": 6230
    },
    {
      "epoch": 0.79,
      "grad_norm": 4.227358341217041,
      "learning_rate": 4.178195202436858e-05,
      "loss": 1.3225,
      "step": 6240
    },
    {
      "epoch": 0.79,
      "grad_norm": 5.8827714920043945,
      "learning_rate": 4.152811270465795e-05,
      "loss": 1.2511,
      "step": 6250
    },
    {
      "epoch": 0.79,
      "grad_norm": 3.9476277828216553,
      "learning_rate": 4.1274273384947335e-05,
      "loss": 1.5796,
      "step": 6260
    },
    {
      "epoch": 0.8,
      "grad_norm": 4.461691379547119,
      "learning_rate": 4.1020434065236706e-05,
      "loss": 1.5421,
      "step": 6270
    },
    {
      "epoch": 0.8,
      "grad_norm": 5.8094000816345215,
      "learning_rate": 4.0766594745526085e-05,
      "loss": 1.375,
      "step": 6280
    },
    {
      "epoch": 0.8,
      "grad_norm": 10.312723159790039,
      "learning_rate": 4.051275542581546e-05,
      "loss": 1.5573,
      "step": 6290
    },
    {
      "epoch": 0.8,
      "grad_norm": 4.335528373718262,
      "learning_rate": 4.025891610610484e-05,
      "loss": 1.4327,
      "step": 6300
    },
    {
      "epoch": 0.8,
      "grad_norm": 3.5542469024658203,
      "learning_rate": 4.000507678639421e-05,
      "loss": 1.5425,
      "step": 6310
    },
    {
      "epoch": 0.8,
      "grad_norm": 4.798366069793701,
      "learning_rate": 3.975123746668359e-05,
      "loss": 1.4258,
      "step": 6320
    },
    {
      "epoch": 0.8,
      "grad_norm": 3.667386293411255,
      "learning_rate": 3.949739814697297e-05,
      "loss": 1.3413,
      "step": 6330
    },
    {
      "epoch": 0.8,
      "grad_norm": 3.238295793533325,
      "learning_rate": 3.924355882726235e-05,
      "loss": 1.4027,
      "step": 6340
    },
    {
      "epoch": 0.81,
      "grad_norm": 3.929523468017578,
      "learning_rate": 3.898971950755172e-05,
      "loss": 1.2402,
      "step": 6350
    },
    {
      "epoch": 0.81,
      "grad_norm": 6.735754013061523,
      "learning_rate": 3.87358801878411e-05,
      "loss": 1.5551,
      "step": 6360
    },
    {
      "epoch": 0.81,
      "grad_norm": 4.205269813537598,
      "learning_rate": 3.8482040868130476e-05,
      "loss": 1.4147,
      "step": 6370
    },
    {
      "epoch": 0.81,
      "grad_norm": 3.3276469707489014,
      "learning_rate": 3.822820154841985e-05,
      "loss": 1.3285,
      "step": 6380
    },
    {
      "epoch": 0.81,
      "grad_norm": 3.4717648029327393,
      "learning_rate": 3.797436222870923e-05,
      "loss": 1.3835,
      "step": 6390
    },
    {
      "epoch": 0.81,
      "grad_norm": 4.054480075836182,
      "learning_rate": 3.7720522908998604e-05,
      "loss": 1.4688,
      "step": 6400
    },
    {
      "epoch": 0.81,
      "grad_norm": 4.074322700500488,
      "learning_rate": 3.746668358928798e-05,
      "loss": 1.2196,
      "step": 6410
    },
    {
      "epoch": 0.81,
      "grad_norm": 3.1848244667053223,
      "learning_rate": 3.7212844269577354e-05,
      "loss": 1.2471,
      "step": 6420
    },
    {
      "epoch": 0.82,
      "grad_norm": 7.543172359466553,
      "learning_rate": 3.695900494986674e-05,
      "loss": 1.2739,
      "step": 6430
    },
    {
      "epoch": 0.82,
      "grad_norm": 6.136667728424072,
      "learning_rate": 3.670516563015611e-05,
      "loss": 1.3118,
      "step": 6440
    },
    {
      "epoch": 0.82,
      "grad_norm": 9.96625804901123,
      "learning_rate": 3.645132631044549e-05,
      "loss": 1.4831,
      "step": 6450
    },
    {
      "epoch": 0.82,
      "grad_norm": 5.042660236358643,
      "learning_rate": 3.619748699073487e-05,
      "loss": 1.3514,
      "step": 6460
    },
    {
      "epoch": 0.82,
      "grad_norm": 6.682054042816162,
      "learning_rate": 3.5943647671024245e-05,
      "loss": 1.4142,
      "step": 6470
    },
    {
      "epoch": 0.82,
      "grad_norm": 8.116195678710938,
      "learning_rate": 3.568980835131362e-05,
      "loss": 1.4027,
      "step": 6480
    },
    {
      "epoch": 0.82,
      "grad_norm": 4.688650608062744,
      "learning_rate": 3.5435969031602995e-05,
      "loss": 1.4135,
      "step": 6490
    },
    {
      "epoch": 0.82,
      "grad_norm": 3.860586166381836,
      "learning_rate": 3.5182129711892373e-05,
      "loss": 1.5015,
      "step": 6500
    },
    {
      "epoch": 0.83,
      "grad_norm": 4.504751205444336,
      "learning_rate": 3.492829039218175e-05,
      "loss": 1.5591,
      "step": 6510
    },
    {
      "epoch": 0.83,
      "grad_norm": 3.183195114135742,
      "learning_rate": 3.467445107247112e-05,
      "loss": 1.539,
      "step": 6520
    },
    {
      "epoch": 0.83,
      "grad_norm": 4.710144996643066,
      "learning_rate": 3.442061175276051e-05,
      "loss": 1.3884,
      "step": 6530
    },
    {
      "epoch": 0.83,
      "grad_norm": 8.262207984924316,
      "learning_rate": 3.416677243304988e-05,
      "loss": 1.363,
      "step": 6540
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.160548448562622,
      "learning_rate": 3.391293311333926e-05,
      "loss": 1.5204,
      "step": 6550
    },
    {
      "epoch": 0.83,
      "grad_norm": 4.16477632522583,
      "learning_rate": 3.365909379362863e-05,
      "loss": 1.4006,
      "step": 6560
    },
    {
      "epoch": 0.83,
      "grad_norm": 9.443854331970215,
      "learning_rate": 3.3405254473918015e-05,
      "loss": 1.4851,
      "step": 6570
    },
    {
      "epoch": 0.84,
      "grad_norm": 5.400372505187988,
      "learning_rate": 3.3151415154207386e-05,
      "loss": 1.4572,
      "step": 6580
    },
    {
      "epoch": 0.84,
      "grad_norm": 3.547933340072632,
      "learning_rate": 3.2897575834496765e-05,
      "loss": 1.2708,
      "step": 6590
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.984677314758301,
      "learning_rate": 3.264373651478614e-05,
      "loss": 1.3829,
      "step": 6600
    },
    {
      "epoch": 0.84,
      "grad_norm": 4.275303840637207,
      "learning_rate": 3.238989719507552e-05,
      "loss": 1.3271,
      "step": 6610
    },
    {
      "epoch": 0.84,
      "grad_norm": 3.4090404510498047,
      "learning_rate": 3.213605787536489e-05,
      "loss": 1.4258,
      "step": 6620
    },
    {
      "epoch": 0.84,
      "grad_norm": 8.5056791305542,
      "learning_rate": 3.188221855565427e-05,
      "loss": 1.5761,
      "step": 6630
    },
    {
      "epoch": 0.84,
      "grad_norm": 3.8824167251586914,
      "learning_rate": 3.162837923594365e-05,
      "loss": 1.4368,
      "step": 6640
    },
    {
      "epoch": 0.84,
      "grad_norm": 3.9242279529571533,
      "learning_rate": 3.137453991623303e-05,
      "loss": 1.6613,
      "step": 6650
    },
    {
      "epoch": 0.85,
      "grad_norm": 4.678797721862793,
      "learning_rate": 3.11207005965224e-05,
      "loss": 1.1546,
      "step": 6660
    },
    {
      "epoch": 0.85,
      "grad_norm": 4.316669464111328,
      "learning_rate": 3.0866861276811784e-05,
      "loss": 1.4016,
      "step": 6670
    },
    {
      "epoch": 0.85,
      "grad_norm": 4.8070807456970215,
      "learning_rate": 3.0613021957101156e-05,
      "loss": 1.2442,
      "step": 6680
    },
    {
      "epoch": 0.85,
      "grad_norm": 5.6265645027160645,
      "learning_rate": 3.035918263739053e-05,
      "loss": 1.4522,
      "step": 6690
    },
    {
      "epoch": 0.85,
      "grad_norm": 3.3352551460266113,
      "learning_rate": 3.0105343317679912e-05,
      "loss": 1.4596,
      "step": 6700
    },
    {
      "epoch": 0.85,
      "grad_norm": 3.0416412353515625,
      "learning_rate": 2.9851503997969287e-05,
      "loss": 1.4744,
      "step": 6710
    },
    {
      "epoch": 0.85,
      "grad_norm": 3.345780372619629,
      "learning_rate": 2.9597664678258662e-05,
      "loss": 1.457,
      "step": 6720
    },
    {
      "epoch": 0.85,
      "grad_norm": 7.28371000289917,
      "learning_rate": 2.9343825358548037e-05,
      "loss": 1.5159,
      "step": 6730
    },
    {
      "epoch": 0.86,
      "grad_norm": 5.678351402282715,
      "learning_rate": 2.908998603883742e-05,
      "loss": 1.5901,
      "step": 6740
    },
    {
      "epoch": 0.86,
      "grad_norm": 3.2417702674865723,
      "learning_rate": 2.8836146719126794e-05,
      "loss": 1.4344,
      "step": 6750
    },
    {
      "epoch": 0.86,
      "grad_norm": 3.3653478622436523,
      "learning_rate": 2.858230739941617e-05,
      "loss": 1.5724,
      "step": 6760
    },
    {
      "epoch": 0.86,
      "grad_norm": 4.30757999420166,
      "learning_rate": 2.832846807970555e-05,
      "loss": 1.2701,
      "step": 6770
    },
    {
      "epoch": 0.86,
      "grad_norm": 3.2243540287017822,
      "learning_rate": 2.8074628759994925e-05,
      "loss": 1.3917,
      "step": 6780
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.2226979732513428,
      "learning_rate": 2.78207894402843e-05,
      "loss": 1.5545,
      "step": 6790
    },
    {
      "epoch": 0.86,
      "grad_norm": 4.1941962242126465,
      "learning_rate": 2.7566950120573675e-05,
      "loss": 1.4566,
      "step": 6800
    },
    {
      "epoch": 0.86,
      "grad_norm": 4.059988975524902,
      "learning_rate": 2.7313110800863057e-05,
      "loss": 1.5081,
      "step": 6810
    },
    {
      "epoch": 0.87,
      "grad_norm": 4.10377311706543,
      "learning_rate": 2.705927148115243e-05,
      "loss": 1.2136,
      "step": 6820
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.89068603515625,
      "learning_rate": 2.6805432161441807e-05,
      "loss": 1.2598,
      "step": 6830
    },
    {
      "epoch": 0.87,
      "grad_norm": 3.943941831588745,
      "learning_rate": 2.6551592841731188e-05,
      "loss": 1.5355,
      "step": 6840
    },
    {
      "epoch": 0.87,
      "grad_norm": 3.2741501331329346,
      "learning_rate": 2.6297753522020563e-05,
      "loss": 1.4501,
      "step": 6850
    },
    {
      "epoch": 0.87,
      "grad_norm": 3.5689260959625244,
      "learning_rate": 2.6043914202309938e-05,
      "loss": 1.4775,
      "step": 6860
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.770787239074707,
      "learning_rate": 2.5790074882599313e-05,
      "loss": 1.562,
      "step": 6870
    },
    {
      "epoch": 0.87,
      "grad_norm": 3.0200130939483643,
      "learning_rate": 2.5536235562888695e-05,
      "loss": 1.5109,
      "step": 6880
    },
    {
      "epoch": 0.87,
      "grad_norm": 3.0552234649658203,
      "learning_rate": 2.528239624317807e-05,
      "loss": 1.5433,
      "step": 6890
    },
    {
      "epoch": 0.88,
      "grad_norm": 4.151317596435547,
      "learning_rate": 2.5028556923467445e-05,
      "loss": 1.6349,
      "step": 6900
    },
    {
      "epoch": 0.88,
      "grad_norm": 3.1454052925109863,
      "learning_rate": 2.4774717603756823e-05,
      "loss": 1.403,
      "step": 6910
    },
    {
      "epoch": 0.88,
      "grad_norm": 5.607127666473389,
      "learning_rate": 2.45208782840462e-05,
      "loss": 1.3917,
      "step": 6920
    },
    {
      "epoch": 0.88,
      "grad_norm": 3.4526844024658203,
      "learning_rate": 2.4267038964335576e-05,
      "loss": 1.5519,
      "step": 6930
    },
    {
      "epoch": 0.88,
      "grad_norm": 3.768263816833496,
      "learning_rate": 2.4013199644624954e-05,
      "loss": 1.3969,
      "step": 6940
    },
    {
      "epoch": 0.88,
      "grad_norm": 4.543030738830566,
      "learning_rate": 2.3759360324914333e-05,
      "loss": 1.3962,
      "step": 6950
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.4804847240448,
      "learning_rate": 2.3505521005203708e-05,
      "loss": 1.1819,
      "step": 6960
    },
    {
      "epoch": 0.88,
      "grad_norm": 3.8121609687805176,
      "learning_rate": 2.3251681685493086e-05,
      "loss": 1.4284,
      "step": 6970
    },
    {
      "epoch": 0.89,
      "grad_norm": 3.1891109943389893,
      "learning_rate": 2.299784236578246e-05,
      "loss": 1.3726,
      "step": 6980
    },
    {
      "epoch": 0.89,
      "grad_norm": 6.5841569900512695,
      "learning_rate": 2.274400304607184e-05,
      "loss": 1.5448,
      "step": 6990
    },
    {
      "epoch": 0.89,
      "grad_norm": 4.014619827270508,
      "learning_rate": 2.2490163726361214e-05,
      "loss": 1.3583,
      "step": 7000
    },
    {
      "epoch": 0.89,
      "grad_norm": 9.018182754516602,
      "learning_rate": 2.2236324406650592e-05,
      "loss": 1.6252,
      "step": 7010
    },
    {
      "epoch": 0.89,
      "grad_norm": 3.882065773010254,
      "learning_rate": 2.198248508693997e-05,
      "loss": 1.5214,
      "step": 7020
    },
    {
      "epoch": 0.89,
      "grad_norm": 6.075860500335693,
      "learning_rate": 2.1728645767229346e-05,
      "loss": 1.38,
      "step": 7030
    },
    {
      "epoch": 0.89,
      "grad_norm": 3.924154281616211,
      "learning_rate": 2.1474806447518724e-05,
      "loss": 1.3631,
      "step": 7040
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.6888327598571777,
      "learning_rate": 2.12209671278081e-05,
      "loss": 1.4105,
      "step": 7050
    },
    {
      "epoch": 0.9,
      "grad_norm": 3.2118449211120605,
      "learning_rate": 2.0967127808097477e-05,
      "loss": 1.3038,
      "step": 7060
    },
    {
      "epoch": 0.9,
      "grad_norm": 4.989441394805908,
      "learning_rate": 2.0713288488386852e-05,
      "loss": 1.4577,
      "step": 7070
    },
    {
      "epoch": 0.9,
      "grad_norm": 4.7419514656066895,
      "learning_rate": 2.0459449168676227e-05,
      "loss": 1.6266,
      "step": 7080
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.31282377243042,
      "learning_rate": 2.0205609848965605e-05,
      "loss": 1.3765,
      "step": 7090
    },
    {
      "epoch": 0.9,
      "grad_norm": 7.379825592041016,
      "learning_rate": 1.995177052925498e-05,
      "loss": 1.4835,
      "step": 7100
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.8801698684692383,
      "learning_rate": 1.969793120954436e-05,
      "loss": 1.5355,
      "step": 7110
    },
    {
      "epoch": 0.9,
      "grad_norm": 3.189394474029541,
      "learning_rate": 1.9444091889833733e-05,
      "loss": 1.2979,
      "step": 7120
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.765812635421753,
      "learning_rate": 1.919025257012311e-05,
      "loss": 1.3576,
      "step": 7130
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.966616153717041,
      "learning_rate": 1.893641325041249e-05,
      "loss": 1.3294,
      "step": 7140
    },
    {
      "epoch": 0.91,
      "grad_norm": 5.068113327026367,
      "learning_rate": 1.8682573930701865e-05,
      "loss": 1.422,
      "step": 7150
    },
    {
      "epoch": 0.91,
      "grad_norm": 5.076344013214111,
      "learning_rate": 1.8428734610991243e-05,
      "loss": 1.3384,
      "step": 7160
    },
    {
      "epoch": 0.91,
      "grad_norm": 3.816561698913574,
      "learning_rate": 1.8174895291280618e-05,
      "loss": 1.4056,
      "step": 7170
    },
    {
      "epoch": 0.91,
      "grad_norm": 5.143000602722168,
      "learning_rate": 1.7921055971569996e-05,
      "loss": 1.3062,
      "step": 7180
    },
    {
      "epoch": 0.91,
      "grad_norm": 4.685690402984619,
      "learning_rate": 1.7667216651859375e-05,
      "loss": 1.4808,
      "step": 7190
    },
    {
      "epoch": 0.91,
      "grad_norm": 4.976213455200195,
      "learning_rate": 1.741337733214875e-05,
      "loss": 1.6932,
      "step": 7200
    },
    {
      "epoch": 0.92,
      "grad_norm": 4.336423873901367,
      "learning_rate": 1.7159538012438128e-05,
      "loss": 1.5095,
      "step": 7210
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.6151559352874756,
      "learning_rate": 1.6905698692727503e-05,
      "loss": 1.2536,
      "step": 7220
    },
    {
      "epoch": 0.92,
      "grad_norm": 4.669784069061279,
      "learning_rate": 1.665185937301688e-05,
      "loss": 1.3681,
      "step": 7230
    },
    {
      "epoch": 0.92,
      "grad_norm": 4.128620147705078,
      "learning_rate": 1.6398020053306256e-05,
      "loss": 1.4489,
      "step": 7240
    },
    {
      "epoch": 0.92,
      "grad_norm": 3.901780366897583,
      "learning_rate": 1.6144180733595634e-05,
      "loss": 1.4663,
      "step": 7250
    },
    {
      "epoch": 0.92,
      "grad_norm": 4.132996082305908,
      "learning_rate": 1.5890341413885013e-05,
      "loss": 1.5954,
      "step": 7260
    },
    {
      "epoch": 0.92,
      "grad_norm": 4.917797565460205,
      "learning_rate": 1.5636502094174387e-05,
      "loss": 1.5232,
      "step": 7270
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.948939561843872,
      "learning_rate": 1.5382662774463766e-05,
      "loss": 1.4935,
      "step": 7280
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.5517311096191406,
      "learning_rate": 1.512882345475314e-05,
      "loss": 1.4894,
      "step": 7290
    },
    {
      "epoch": 0.93,
      "grad_norm": 4.336464881896973,
      "learning_rate": 1.4874984135042519e-05,
      "loss": 1.4248,
      "step": 7300
    },
    {
      "epoch": 0.93,
      "grad_norm": 3.445969343185425,
      "learning_rate": 1.4621144815331897e-05,
      "loss": 1.4508,
      "step": 7310
    },
    {
      "epoch": 0.93,
      "grad_norm": 4.78020715713501,
      "learning_rate": 1.4367305495621272e-05,
      "loss": 1.6083,
      "step": 7320
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.9415946006774902,
      "learning_rate": 1.411346617591065e-05,
      "loss": 1.2785,
      "step": 7330
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.322443962097168,
      "learning_rate": 1.3859626856200025e-05,
      "loss": 1.3565,
      "step": 7340
    },
    {
      "epoch": 0.93,
      "grad_norm": 3.768035888671875,
      "learning_rate": 1.3605787536489404e-05,
      "loss": 1.4006,
      "step": 7350
    },
    {
      "epoch": 0.93,
      "grad_norm": 4.007413864135742,
      "learning_rate": 1.3351948216778779e-05,
      "loss": 1.342,
      "step": 7360
    },
    {
      "epoch": 0.94,
      "grad_norm": 4.3850016593933105,
      "learning_rate": 1.3098108897068157e-05,
      "loss": 1.3384,
      "step": 7370
    },
    {
      "epoch": 0.94,
      "grad_norm": 3.6999621391296387,
      "learning_rate": 1.2844269577357535e-05,
      "loss": 1.2097,
      "step": 7380
    },
    {
      "epoch": 0.94,
      "grad_norm": 3.29571270942688,
      "learning_rate": 1.259043025764691e-05,
      "loss": 1.4446,
      "step": 7390
    },
    {
      "epoch": 0.94,
      "grad_norm": 5.58977746963501,
      "learning_rate": 1.2336590937936287e-05,
      "loss": 1.3898,
      "step": 7400
    },
    {
      "epoch": 0.94,
      "grad_norm": 4.0461883544921875,
      "learning_rate": 1.2082751618225665e-05,
      "loss": 1.4784,
      "step": 7410
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.805051565170288,
      "learning_rate": 1.182891229851504e-05,
      "loss": 1.2208,
      "step": 7420
    },
    {
      "epoch": 0.94,
      "grad_norm": 4.6995320320129395,
      "learning_rate": 1.1575072978804417e-05,
      "loss": 1.3994,
      "step": 7430
    },
    {
      "epoch": 0.94,
      "grad_norm": 10.376192092895508,
      "learning_rate": 1.1321233659093793e-05,
      "loss": 1.5278,
      "step": 7440
    },
    {
      "epoch": 0.95,
      "grad_norm": 5.094559192657471,
      "learning_rate": 1.106739433938317e-05,
      "loss": 1.4135,
      "step": 7450
    },
    {
      "epoch": 0.95,
      "grad_norm": 4.755929470062256,
      "learning_rate": 1.0813555019672546e-05,
      "loss": 1.5636,
      "step": 7460
    },
    {
      "epoch": 0.95,
      "grad_norm": 3.7872653007507324,
      "learning_rate": 1.0559715699961925e-05,
      "loss": 1.5482,
      "step": 7470
    },
    {
      "epoch": 0.95,
      "grad_norm": 6.78096866607666,
      "learning_rate": 1.0305876380251301e-05,
      "loss": 1.3162,
      "step": 7480
    },
    {
      "epoch": 0.95,
      "grad_norm": 3.0629141330718994,
      "learning_rate": 1.0052037060540678e-05,
      "loss": 1.4095,
      "step": 7490
    },
    {
      "epoch": 0.95,
      "grad_norm": 5.512688636779785,
      "learning_rate": 9.798197740830055e-06,
      "loss": 1.3636,
      "step": 7500
    },
    {
      "epoch": 0.95,
      "grad_norm": 3.0581135749816895,
      "learning_rate": 9.544358421119431e-06,
      "loss": 1.4433,
      "step": 7510
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.6922216415405273,
      "learning_rate": 9.290519101408808e-06,
      "loss": 1.3214,
      "step": 7520
    },
    {
      "epoch": 0.96,
      "grad_norm": 6.906022071838379,
      "learning_rate": 9.036679781698186e-06,
      "loss": 1.4021,
      "step": 7530
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.9531195163726807,
      "learning_rate": 8.782840461987563e-06,
      "loss": 1.2911,
      "step": 7540
    },
    {
      "epoch": 0.96,
      "grad_norm": 5.3830766677856445,
      "learning_rate": 8.52900114227694e-06,
      "loss": 1.2978,
      "step": 7550
    },
    {
      "epoch": 0.96,
      "grad_norm": 5.122459411621094,
      "learning_rate": 8.275161822566316e-06,
      "loss": 1.4597,
      "step": 7560
    },
    {
      "epoch": 0.96,
      "grad_norm": 3.923380136489868,
      "learning_rate": 8.021322502855692e-06,
      "loss": 1.3357,
      "step": 7570
    },
    {
      "epoch": 0.96,
      "grad_norm": 4.742123126983643,
      "learning_rate": 7.767483183145069e-06,
      "loss": 1.4275,
      "step": 7580
    },
    {
      "epoch": 0.96,
      "grad_norm": 6.29902982711792,
      "learning_rate": 7.513643863434447e-06,
      "loss": 1.4594,
      "step": 7590
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.524207592010498,
      "learning_rate": 7.259804543723823e-06,
      "loss": 1.279,
      "step": 7600
    },
    {
      "epoch": 0.97,
      "grad_norm": 3.8051092624664307,
      "learning_rate": 7.0059652240132e-06,
      "loss": 1.3356,
      "step": 7610
    },
    {
      "epoch": 0.97,
      "grad_norm": 3.4881269931793213,
      "learning_rate": 6.752125904302576e-06,
      "loss": 1.5965,
      "step": 7620
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.251070022583008,
      "learning_rate": 6.498286584591953e-06,
      "loss": 1.4381,
      "step": 7630
    },
    {
      "epoch": 0.97,
      "grad_norm": 3.6103620529174805,
      "learning_rate": 6.24444726488133e-06,
      "loss": 1.6609,
      "step": 7640
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.767251968383789,
      "learning_rate": 5.990607945170707e-06,
      "loss": 1.5124,
      "step": 7650
    },
    {
      "epoch": 0.97,
      "grad_norm": 6.208243370056152,
      "learning_rate": 5.736768625460084e-06,
      "loss": 1.4766,
      "step": 7660
    },
    {
      "epoch": 0.97,
      "grad_norm": 5.117580890655518,
      "learning_rate": 5.482929305749461e-06,
      "loss": 1.3937,
      "step": 7670
    },
    {
      "epoch": 0.97,
      "grad_norm": 3.3735218048095703,
      "learning_rate": 5.229089986038838e-06,
      "loss": 1.5315,
      "step": 7680
    },
    {
      "epoch": 0.98,
      "grad_norm": 6.7446980476379395,
      "learning_rate": 4.975250666328214e-06,
      "loss": 1.3013,
      "step": 7690
    },
    {
      "epoch": 0.98,
      "grad_norm": 3.148449420928955,
      "learning_rate": 4.721411346617592e-06,
      "loss": 1.4448,
      "step": 7700
    },
    {
      "epoch": 0.98,
      "grad_norm": 3.820034980773926,
      "learning_rate": 4.467572026906968e-06,
      "loss": 1.367,
      "step": 7710
    },
    {
      "epoch": 0.98,
      "grad_norm": 4.032217502593994,
      "learning_rate": 4.213732707196345e-06,
      "loss": 1.4241,
      "step": 7720
    },
    {
      "epoch": 0.98,
      "grad_norm": 4.149670600891113,
      "learning_rate": 3.9598933874857215e-06,
      "loss": 1.2572,
      "step": 7730
    },
    {
      "epoch": 0.98,
      "grad_norm": 3.500764846801758,
      "learning_rate": 3.7060540677750986e-06,
      "loss": 1.3385,
      "step": 7740
    },
    {
      "epoch": 0.98,
      "grad_norm": 4.091480731964111,
      "learning_rate": 3.452214748064475e-06,
      "loss": 1.232,
      "step": 7750
    },
    {
      "epoch": 0.98,
      "grad_norm": 5.816611289978027,
      "learning_rate": 3.198375428353852e-06,
      "loss": 1.4662,
      "step": 7760
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.808367967605591,
      "learning_rate": 2.944536108643229e-06,
      "loss": 1.2795,
      "step": 7770
    },
    {
      "epoch": 0.99,
      "grad_norm": 3.055793523788452,
      "learning_rate": 2.690696788932606e-06,
      "loss": 1.4171,
      "step": 7780
    },
    {
      "epoch": 0.99,
      "grad_norm": 4.603242874145508,
      "learning_rate": 2.4368574692219825e-06,
      "loss": 1.3899,
      "step": 7790
    },
    {
      "epoch": 0.99,
      "grad_norm": 11.352325439453125,
      "learning_rate": 2.1830181495113595e-06,
      "loss": 1.3536,
      "step": 7800
    },
    {
      "epoch": 0.99,
      "grad_norm": 4.704523086547852,
      "learning_rate": 1.9291788298007365e-06,
      "loss": 1.1343,
      "step": 7810
    },
    {
      "epoch": 0.99,
      "grad_norm": 3.015672206878662,
      "learning_rate": 1.675339510090113e-06,
      "loss": 1.4047,
      "step": 7820
    },
    {
      "epoch": 0.99,
      "grad_norm": 4.876709461212158,
      "learning_rate": 1.42150019037949e-06,
      "loss": 1.2876,
      "step": 7830
    },
    {
      "epoch": 0.99,
      "grad_norm": 3.798083782196045,
      "learning_rate": 1.1676608706688665e-06,
      "loss": 1.2134,
      "step": 7840
    },
    {
      "epoch": 1.0,
      "grad_norm": 3.213796377182007,
      "learning_rate": 9.138215509582436e-07,
      "loss": 1.5058,
      "step": 7850
    },
    {
      "epoch": 1.0,
      "grad_norm": 7.086016654968262,
      "learning_rate": 6.599822312476203e-07,
      "loss": 1.3447,
      "step": 7860
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.5903098583221436,
      "learning_rate": 4.0614291153699706e-07,
      "loss": 1.5082,
      "step": 7870
    }
  ],
  "logging_steps": 10,
  "max_steps": 7879,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "total_flos": 3.4454687012880384e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
